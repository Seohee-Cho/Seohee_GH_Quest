{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix & metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# classification 위한 임의의 데이터 생성 -> X: 2개 feature, y:binary 인 데이터 샘플 100개\n",
    "X, y = make_classification(n_samples=100, n_features=2, n_informative=2, n_redundant=0) #x값에 2개의 feature 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_score</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.960712</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.579686</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.709356</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.719817</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.494104</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_score  y_pred    y\n",
       "0  10.960712     1.0  1.0\n",
       "1   8.579686     1.0  1.0\n",
       "2   7.709356     1.0  1.0\n",
       "3   6.719817     1.0  1.0\n",
       "4   6.494104     1.0  1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_score</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-5.618467</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-5.644874</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-5.836798</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>-7.183429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>-8.134024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_score  y_pred    y\n",
       "95 -5.618467     0.0  0.0\n",
       "96 -5.644874     0.0  0.0\n",
       "97 -5.836798     0.0  0.0\n",
       "98 -7.183429     0.0  0.0\n",
       "99 -8.134024     0.0  0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = LogisticRegression().fit(X,y)\n",
    "y_pred = model.predict(X)\n",
    "y_score = model.decision_function(X)  # decision_function(): 판별함수 값 계산\n",
    "# y_score(계산된 판별함수 값)가 양수이면 y=1, 음수이면 y=0으로 분류\n",
    "\n",
    "# 데이터프레임 형태로 확인해 보자\n",
    "df = pd.DataFrame(np.vstack([y_score, y_pred, y]).T,\n",
    "                  columns=[\"y_score\", \"y_pred\", \"y\"])\n",
    "df = df.sort_values(\"y_score\", ascending=False).reset_index(drop=True)\n",
    "display(df.head(), df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[46  5]\n",
      " [ 2 47]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.93"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9038461538461539"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9591836734693877"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9306930693069307"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93        51\n",
      "           1       0.90      0.96      0.93        49\n",
      "\n",
      "   micro avg       0.93      0.93      0.93       100\n",
      "   macro avg       0.93      0.93      0.93       100\n",
      "weighted avg       0.93      0.93      0.93       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "# 지표 확인\n",
    "print(confusion_matrix(y, y_pred)) # TP FN FP TN\n",
    "display(accuracy_score(y, y_pred), precision_score(y, y_pred), recall_score(y, y_pred), f1_score(y, y_pred))\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_score</th>\n",
       "      <th>y_hat</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>-1.504060</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>-1.586684</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>-1.711021</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>-1.761630</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>-1.968663</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>-2.147105</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>-2.287081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>-2.425482</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_score  y_hat    y\n",
       "66 -1.504060    1.0  0.0\n",
       "67 -1.586684    1.0  0.0\n",
       "68 -1.711021    1.0  0.0\n",
       "69 -1.761630    1.0  0.0\n",
       "70 -1.968663    1.0  0.0\n",
       "71 -2.147105    0.0  0.0\n",
       "72 -2.287081    0.0  0.0\n",
       "73 -2.425482    0.0  0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[29 22]\n",
      " [ 0 49]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.57      0.72        51\n",
      "          1       0.69      1.00      0.82        49\n",
      "\n",
      "avg / total       0.85      0.78      0.77       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# threshold를 0이 아닌 -2로 지정해 보자 \n",
    "lower_threshold = model.decision_function(X) > -2 #-2보다 큰경우 1로 분류, -2보다 작은경우 0으로 분류\n",
    "\n",
    "df2 = pd.DataFrame(np.vstack([y_score, lower_threshold, y]).T,\n",
    "                  columns=[\"y_score\", \"y_hat\", \"y\"])\n",
    "df2 = df2.sort_values(\"y_score\", ascending=False).reset_index(drop=True)\n",
    "display(df2[(df2['y_score']> -2.5) & (df2['y_score']<-1.5)])\n",
    "\n",
    "print(confusion_matrix(y, lower_threshold))\n",
    "print(classification_report(y, lower_threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC, PR 곡선 그리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X, y = make_classification(n_samples=500, n_features=2, n_informative=2, n_redundant=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# model = LogisticRegression()\n",
    "\n",
    "y_score = model.fit(X_train, y_train).decision_function(X_test)\n",
    "\n",
    "# decision_function()을 사용할 수 없는 모델의 경우 y_score 대신 predict_proba()로 확률값을 구해줌\n",
    "# probs = model.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "# probs = probs[:, 1] # 0,1 중 1로 분류될 확률\n",
    "\n",
    "# calculate AUC\n",
    "roc_auc = roc_auc_score(y_test, y_score)\n",
    "\n",
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_score)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, lw=2, color='darkorange', label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate = Recall')\n",
    "plt.ylabel('True Positive Rate = Sensitivity')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "\n",
    "# calculate precision-recall AUC\n",
    "pr_auc = auc(recall, precision)\n",
    "\n",
    "plt.plot(recall, precision, lw=2, color='darkorange', label='PR curve (area = %0.2f)' % pr_auc)\n",
    "plt.plot([0, 1], [0.5, 0.5], linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.22797043 -0.65989727]\n",
      " [ 0.23729822  0.53098715]\n",
      " [ 0.90816202  0.29764902]\n",
      " ...\n",
      " [ 1.60151187  0.70757717]\n",
      " [ 0.09376888  0.38732615]\n",
      " [-2.36542865 -1.5726754 ]] [0 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 1 0 0 0 0\n",
      " 1 0 1 1 1 0 1 0 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1\n",
      " 1 0 0 1 0 0 0 1 0 0 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 0 1 0 1 1 1 1\n",
      " 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 1 0 1 0 0 1 1 0 1 1 1\n",
      " 1 1 1 0 1 1 0 1 1 0 0 0 1 1 0 0 1 1 1 0 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1\n",
      " 0 1 0 0 1 1 0 0 1 0 1 0 1 0 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 0 0 1 0 1 1 1\n",
      " 1 0 0 0 0 0 1 1 0 1 1 0 0 1 1 1 1 0 0 1 1 0 0 0 0 1 0 0 1 0 0 0 1 1 1 0 0\n",
      " 0 0 1 1 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 0 1 0 0 1 1 1 0 0 0 0 1 1 0 0 1\n",
      " 0 1 0 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 1 1 1 1 0\n",
      " 1]\n",
      "[[-2.30498574 -1.65681633]\n",
      " [-2.03490046 -1.53587567]\n",
      " [-0.39989496 -0.70292241]\n",
      " ...\n",
      " [ 1.67689305  1.0876581 ]\n",
      " [ 1.02288554 -0.52887796]\n",
      " [-0.58961569  1.16926136]] [0 1 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 1 1 0 0 1 0\n",
      " 0 0 0 1 1 0 1 0 0 0 1 1 0 0 0 0 1 0 1 1 1 1 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1\n",
      " 0 0 1 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0 0 1 1 0 1 1 1 0 0 1 0 0 1 0 1\n",
      " 0 0 1 1 1 1 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 1 1 0 0 1 1 1 0 0 1 1 0 0 0 0 0\n",
      " 0 1 0 0 0 1 1 0 0 1 0 1 1 0 0 0 1 0 0 0 0 1 1 0 1 0 0 1 0 0 0 1 1 1 1 1 0\n",
      " 0 0 1 1 0 0 0 0 0 1 0 1 0 1 0 0 1 1 0 1 1 0 1 1 1 0 0 0 0 1 1 1 0 1 0 1 1\n",
      " 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0\n",
      " 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 0 1 0 1 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 1 1 0 1 0 0 1 1 1 1 1 1 0 0 0 1 1 0 0 1 0 0 0 1 1 0 1 1 0 1 1 0]\n",
      "[[-0.22797043 -0.65989727]\n",
      " [-2.30498574 -1.65681633]\n",
      " [-2.03490046 -1.53587567]\n",
      " ...\n",
      " [-2.36542865 -1.5726754 ]\n",
      " [ 1.02288554 -0.52887796]\n",
      " [-0.58961569  1.16926136]] [0 1 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 0 1 1 0 1 0 0 0 0 0 1 1 1 1 0\n",
      " 0 1 0 0 1 1 1 1 1 1 1 0 1 0 0 1 1 1 0 0 0 1 1 1 1 1 0 0 1 0 1 0 1 0 1 0 0\n",
      " 0 0 1 1 1 1 1 1 0 0 1 0 1 0 1 1 0 1 0 1 0 1 1 1 0 0 0 0 0 1 1 0 0 0 1 1 1\n",
      " 1 0 1 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 1 1 0 1 1 0 1 1 1 0 0 0 0 0 0 0 1 0\n",
      " 0 0 1 0 1 0 1 0 1 0 0 0 1 0 1 1 1 0 1 0 0 0 1 0 1 1 1 0 1 0 1 0 0 0 0 1 1\n",
      " 1 1 0 1 1 0 0 0 0 0 0 0 1 1 0 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 0 1 0 1 1 1 1\n",
      " 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 1 0 1 0 1 1 0 1 1 0 1 1 1 0 0 0 0 1 1 1 1\n",
      " 1 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0 1 1 1 0 1 0 1 0 1 1 1 0 0 0 0 0 1 1 0 0 1\n",
      " 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 0 1 0 1 0 0 1 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# kFold 모듈\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "cv = KFold(n_splits=3, shuffle=True, random_state=0) #1과 0 값 섞어주기\n",
    "for train_index, test_index in cv.split(X):\n",
    "    print(X[train_index], y[test_index])\n",
    "# cv.split(X)는 X를 k-fold로 나눈 뒤 각 fold에서의 (train_index, test_index)를 반환하는 iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.955, 0.92 , 0.96 , 0.95 , 0.93 ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cross_val_score 모듈\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=0) # target이 골고루 분포되도록 shuffle 옵션\n",
    "scores = cross_val_score(LogisticRegression(), X, y, cv=kfold)\n",
    "# cross_val_score(모델, 데이터, 타깃)\n",
    "scores # 각 fold에 대한 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.93413174, 0.94594595, 0.94594595])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(LogisticRegression(), X, y) \n",
    "scores \n",
    "# cross_val_score의 기본값은 k=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92537313, 0.94029851, 0.95      , 0.95477387, 0.93969849])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(LogisticRegression(), X, y, cv=5)\n",
    "scores\n",
    "# cross_val_score는 기본적으로 분류 모델에 대해 StratifiedKfold(그냥 kfold 보다는 데이터 불균형 많을 때 사용하면 better) 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9420288007200179"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.00010236245330868884"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(scores.mean(), scores.var()) # 교차검증 점수들의 평균과 분산 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 딕셔너리 형태로 시험할 파라미터를 지정\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100], 'penalty': ['l1','l2']}\n",
    "# 로지스틱 회귀의 경우 주요 파라미터: C, penalty 등\n",
    "# 이 경우 파라미터'C'값 6개, 'penalty'값 2개의 조합 => 총 6x2=12번 모델 돌리게 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적의 파라미터:  {'C': 10, 'penalty': 'l1'}\n",
      "최고 성능 모델:  LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "최고 교차검증 점수: 0.94\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5) # 보통 교차검증을 사용한 그리드 서치를 시행! 보통 5번을 많이 사용\n",
    "# GridSearchCV(모델, 파라미터 딕셔너리)\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print('최적의 파라미터: ', grid_search.best_params_)\n",
    "print('최고 성능 모델: ', grid_search.best_estimator_)\n",
    "print('최고 교차검증 점수: {:.2f}'.format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean_fit_time</th>\n",
       "      <td>0.00158787</td>\n",
       "      <td>0.00228257</td>\n",
       "      <td>0.00205574</td>\n",
       "      <td>0.00188508</td>\n",
       "      <td>0.00192738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_fit_time</th>\n",
       "      <td>0.00057915</td>\n",
       "      <td>0.000507351</td>\n",
       "      <td>0.000223673</td>\n",
       "      <td>0.000198442</td>\n",
       "      <td>0.000470564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_score_time</th>\n",
       "      <td>0.000712252</td>\n",
       "      <td>0.000694942</td>\n",
       "      <td>0.000629807</td>\n",
       "      <td>0.000688791</td>\n",
       "      <td>0.000637484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_score_time</th>\n",
       "      <td>0.000266401</td>\n",
       "      <td>0.000242016</td>\n",
       "      <td>0.000193803</td>\n",
       "      <td>0.000382067</td>\n",
       "      <td>0.000204024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_C</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_penalty</th>\n",
       "      <td>l1</td>\n",
       "      <td>l2</td>\n",
       "      <td>l1</td>\n",
       "      <td>l2</td>\n",
       "      <td>l1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <td>{'C': 0.001, 'penalty': 'l1'}</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l2'}</td>\n",
       "      <td>{'C': 0.01, 'penalty': 'l1'}</td>\n",
       "      <td>{'C': 0.01, 'penalty': 'l2'}</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l1'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_test_score</th>\n",
       "      <td>0.502488</td>\n",
       "      <td>0.930348</td>\n",
       "      <td>0.935323</td>\n",
       "      <td>0.935323</td>\n",
       "      <td>0.935323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_score</th>\n",
       "      <td>0.502488</td>\n",
       "      <td>0.935323</td>\n",
       "      <td>0.935323</td>\n",
       "      <td>0.935323</td>\n",
       "      <td>0.930348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_test_score</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_test_score</th>\n",
       "      <td>0.502513</td>\n",
       "      <td>0.939698</td>\n",
       "      <td>0.939698</td>\n",
       "      <td>0.939698</td>\n",
       "      <td>0.954774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_test_score</th>\n",
       "      <td>0.502513</td>\n",
       "      <td>0.939698</td>\n",
       "      <td>0.939698</td>\n",
       "      <td>0.939698</td>\n",
       "      <td>0.939698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_score</th>\n",
       "      <td>0.502</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_score</th>\n",
       "      <td>0.00100006</td>\n",
       "      <td>0.0082557</td>\n",
       "      <td>0.0072683</td>\n",
       "      <td>0.0072683</td>\n",
       "      <td>0.00908701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_train_score</th>\n",
       "      <td>0.501877</td>\n",
       "      <td>0.94368</td>\n",
       "      <td>0.942428</td>\n",
       "      <td>0.942428</td>\n",
       "      <td>0.944931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_train_score</th>\n",
       "      <td>0.501877</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.942428</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.946183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_train_score</th>\n",
       "      <td>0.5025</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_train_score</th>\n",
       "      <td>0.501873</td>\n",
       "      <td>0.938826</td>\n",
       "      <td>0.941323</td>\n",
       "      <td>0.941323</td>\n",
       "      <td>0.940075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_train_score</th>\n",
       "      <td>0.501873</td>\n",
       "      <td>0.938826</td>\n",
       "      <td>0.941323</td>\n",
       "      <td>0.941323</td>\n",
       "      <td>0.94382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_score</th>\n",
       "      <td>0.502</td>\n",
       "      <td>0.940002</td>\n",
       "      <td>0.941001</td>\n",
       "      <td>0.94125</td>\n",
       "      <td>0.943252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_train_score</th>\n",
       "      <td>0.000250008</td>\n",
       "      <td>0.0021876</td>\n",
       "      <td>0.00181866</td>\n",
       "      <td>0.000770251</td>\n",
       "      <td>0.00227304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                0  \\\n",
       "mean_fit_time                          0.00158787   \n",
       "std_fit_time                           0.00057915   \n",
       "mean_score_time                       0.000712252   \n",
       "std_score_time                        0.000266401   \n",
       "param_C                                     0.001   \n",
       "param_penalty                                  l1   \n",
       "params              {'C': 0.001, 'penalty': 'l1'}   \n",
       "split0_test_score                        0.502488   \n",
       "split1_test_score                        0.502488   \n",
       "split2_test_score                             0.5   \n",
       "split3_test_score                        0.502513   \n",
       "split4_test_score                        0.502513   \n",
       "mean_test_score                             0.502   \n",
       "std_test_score                         0.00100006   \n",
       "rank_test_score                                12   \n",
       "split0_train_score                       0.501877   \n",
       "split1_train_score                       0.501877   \n",
       "split2_train_score                         0.5025   \n",
       "split3_train_score                       0.501873   \n",
       "split4_train_score                       0.501873   \n",
       "mean_train_score                            0.502   \n",
       "std_train_score                       0.000250008   \n",
       "\n",
       "                                                1  \\\n",
       "mean_fit_time                          0.00228257   \n",
       "std_fit_time                          0.000507351   \n",
       "mean_score_time                       0.000694942   \n",
       "std_score_time                        0.000242016   \n",
       "param_C                                     0.001   \n",
       "param_penalty                                  l2   \n",
       "params              {'C': 0.001, 'penalty': 'l2'}   \n",
       "split0_test_score                        0.930348   \n",
       "split1_test_score                        0.935323   \n",
       "split2_test_score                           0.955   \n",
       "split3_test_score                        0.939698   \n",
       "split4_test_score                        0.939698   \n",
       "mean_test_score                              0.94   \n",
       "std_test_score                          0.0082557   \n",
       "rank_test_score                                10   \n",
       "split0_train_score                        0.94368   \n",
       "split1_train_score                       0.941176   \n",
       "split2_train_score                         0.9375   \n",
       "split3_train_score                       0.938826   \n",
       "split4_train_score                       0.938826   \n",
       "mean_train_score                         0.940002   \n",
       "std_train_score                         0.0021876   \n",
       "\n",
       "                                               2  \\\n",
       "mean_fit_time                         0.00205574   \n",
       "std_fit_time                         0.000223673   \n",
       "mean_score_time                      0.000629807   \n",
       "std_score_time                       0.000193803   \n",
       "param_C                                     0.01   \n",
       "param_penalty                                 l1   \n",
       "params              {'C': 0.01, 'penalty': 'l1'}   \n",
       "split0_test_score                       0.935323   \n",
       "split1_test_score                       0.935323   \n",
       "split2_test_score                          0.955   \n",
       "split3_test_score                       0.939698   \n",
       "split4_test_score                       0.939698   \n",
       "mean_test_score                            0.941   \n",
       "std_test_score                         0.0072683   \n",
       "rank_test_score                                7   \n",
       "split0_train_score                      0.942428   \n",
       "split1_train_score                      0.942428   \n",
       "split2_train_score                        0.9375   \n",
       "split3_train_score                      0.941323   \n",
       "split4_train_score                      0.941323   \n",
       "mean_train_score                        0.941001   \n",
       "std_train_score                       0.00181866   \n",
       "\n",
       "                                               3                            4  \n",
       "mean_fit_time                         0.00188508                   0.00192738  \n",
       "std_fit_time                         0.000198442                  0.000470564  \n",
       "mean_score_time                      0.000688791                  0.000637484  \n",
       "std_score_time                       0.000382067                  0.000204024  \n",
       "param_C                                     0.01                          0.1  \n",
       "param_penalty                                 l2                           l1  \n",
       "params              {'C': 0.01, 'penalty': 'l2'}  {'C': 0.1, 'penalty': 'l1'}  \n",
       "split0_test_score                       0.935323                     0.935323  \n",
       "split1_test_score                       0.935323                     0.930348  \n",
       "split2_test_score                          0.955                         0.95  \n",
       "split3_test_score                       0.939698                     0.954774  \n",
       "split4_test_score                       0.939698                     0.939698  \n",
       "mean_test_score                            0.941                        0.942  \n",
       "std_test_score                         0.0072683                   0.00908701  \n",
       "rank_test_score                                7                            5  \n",
       "split0_train_score                      0.942428                     0.944931  \n",
       "split1_train_score                      0.941176                     0.946183  \n",
       "split2_train_score                          0.94                      0.94125  \n",
       "split3_train_score                      0.941323                     0.940075  \n",
       "split4_train_score                      0.941323                      0.94382  \n",
       "mean_train_score                         0.94125                     0.943252  \n",
       "std_train_score                      0.000770251                   0.00227304  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 데이터프레임으로 교차검증 결과 확인해보자 (grid_search.cv_results_)\n",
    "pd.set_option('display.max_columns', None)\n",
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "# 처음 다섯 개 행 출력\n",
    "display(np.transpose(results.head())) #test score나 train score가 증가하는지, 시간은 어떻게 변하는지 보는게..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['data']\n",
    "X_1 = X[:, 0].reshape(-1,1)\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = (y==0).astype(np.int)\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_1, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "##mean radius 변수 사용\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_1, y)\n",
    "\n",
    "y_score = log_reg.fit(X_train, y_train).decision_function(X_test)\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_score)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_score)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, lw=2, color='darkorange', label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate = Recall')\n",
    "plt.ylabel('True Positive Rate = Sensitivity')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##mean texture 변수 사용\n",
    "X = data['data']\n",
    "X_2 = X[:, 1].reshape(-1,1)\n",
    "y = data['target']\n",
    "\n",
    "y = (y==0).astype(np.int)\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_2, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_2, y)\n",
    "y_score = log_reg.fit(X_train, y_train).decision_function(X_test)\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_score)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_score)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, lw=2, color='darkorange', label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate = Recall')\n",
    "plt.ylabel('True Positive Rate = Sensitivity')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mean radius 변수를 사용하는 모델이 AUC 값이 더 높으므로 해당 모델 선택."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17.99 ]\n",
      " [19.69 ]\n",
      " [11.42 ]\n",
      " [20.29 ]\n",
      " [12.45 ]\n",
      " [18.25 ]\n",
      " [13.71 ]\n",
      " [13.   ]\n",
      " [12.46 ]\n",
      " [15.78 ]\n",
      " [15.85 ]\n",
      " [14.68 ]\n",
      " [19.81 ]\n",
      " [13.54 ]\n",
      " [13.08 ]\n",
      " [15.34 ]\n",
      " [21.16 ]\n",
      " [16.65 ]\n",
      " [17.14 ]\n",
      " [14.58 ]\n",
      " [18.61 ]\n",
      " [15.3  ]\n",
      " [17.57 ]\n",
      " [18.63 ]\n",
      " [17.02 ]\n",
      " [19.27 ]\n",
      " [16.13 ]\n",
      " [16.74 ]\n",
      " [14.25 ]\n",
      " [14.99 ]\n",
      " [13.48 ]\n",
      " [13.44 ]\n",
      " [10.95 ]\n",
      " [19.07 ]\n",
      " [13.28 ]\n",
      " [13.17 ]\n",
      " [13.17 ]\n",
      " [12.05 ]\n",
      " [13.49 ]\n",
      " [11.76 ]\n",
      " [13.64 ]\n",
      " [11.94 ]\n",
      " [18.22 ]\n",
      " [15.1  ]\n",
      " [11.52 ]\n",
      " [19.21 ]\n",
      " [14.71 ]\n",
      " [13.05 ]\n",
      " [ 8.618]\n",
      " [10.17 ]\n",
      " [ 8.598]\n",
      " [14.25 ]\n",
      " [ 9.173]\n",
      " [14.78 ]\n",
      " [11.31 ]\n",
      " [ 9.029]\n",
      " [12.78 ]\n",
      " [18.94 ]\n",
      " [17.2  ]\n",
      " [13.8  ]\n",
      " [12.31 ]\n",
      " [13.53 ]\n",
      " [18.05 ]\n",
      " [12.86 ]\n",
      " [11.45 ]\n",
      " [13.34 ]\n",
      " [25.22 ]\n",
      " [19.1  ]\n",
      " [12.   ]\n",
      " [14.48 ]\n",
      " [19.02 ]\n",
      " [12.36 ]\n",
      " [15.37 ]\n",
      " [13.27 ]\n",
      " [13.45 ]\n",
      " [15.06 ]\n",
      " [20.26 ]\n",
      " [12.18 ]\n",
      " [ 9.787]\n",
      " [11.6  ]\n",
      " [14.42 ]\n",
      " [13.61 ]\n",
      " [ 6.981]\n",
      " [10.49 ]\n",
      " [13.11 ]\n",
      " [11.64 ]\n",
      " [11.34 ]\n",
      " [ 9.777]\n",
      " [12.63 ]\n",
      " [14.26 ]\n",
      " [10.51 ]\n",
      " [ 8.726]\n",
      " [11.93 ]\n",
      " [ 8.95 ]\n",
      " [14.87 ]\n",
      " [17.95 ]\n",
      " [11.41 ]\n",
      " [18.66 ]\n",
      " [24.25 ]\n",
      " [14.5  ]\n",
      " [13.37 ]\n",
      " [13.85 ]\n",
      " [13.61 ]\n",
      " [15.1  ]\n",
      " [19.79 ]\n",
      " [12.19 ]\n",
      " [15.46 ]\n",
      " [15.71 ]\n",
      " [12.77 ]\n",
      " [11.71 ]\n",
      " [11.43 ]\n",
      " [14.95 ]\n",
      " [11.28 ]\n",
      " [16.11 ]\n",
      " [12.9  ]\n",
      " [10.75 ]\n",
      " [11.9  ]\n",
      " [11.8  ]\n",
      " [14.95 ]\n",
      " [14.44 ]\n",
      " [13.74 ]\n",
      " [13.   ]\n",
      " [ 8.219]\n",
      " [ 9.731]\n",
      " [11.15 ]\n",
      " [13.15 ]\n",
      " [12.25 ]\n",
      " [17.68 ]\n",
      " [12.06 ]\n",
      " [11.75 ]\n",
      " [19.19 ]\n",
      " [19.59 ]\n",
      " [12.34 ]\n",
      " [23.27 ]\n",
      " [10.8  ]\n",
      " [16.78 ]\n",
      " [17.47 ]\n",
      " [14.97 ]\n",
      " [13.43 ]\n",
      " [11.08 ]\n",
      " [10.66 ]\n",
      " [ 9.904]\n",
      " [16.46 ]\n",
      " [13.01 ]\n",
      " [27.22 ]\n",
      " [21.09 ]\n",
      " [15.7  ]\n",
      " [11.41 ]\n",
      " [15.28 ]\n",
      " [10.08 ]\n",
      " [18.31 ]\n",
      " [11.71 ]\n",
      " [12.3  ]\n",
      " [14.22 ]\n",
      " [12.77 ]\n",
      " [ 9.72 ]\n",
      " [12.34 ]\n",
      " [12.91 ]\n",
      " [18.08 ]\n",
      " [19.18 ]\n",
      " [14.45 ]\n",
      " [12.23 ]\n",
      " [17.54 ]\n",
      " [23.29 ]\n",
      " [13.81 ]\n",
      " [12.47 ]\n",
      " [ 9.876]\n",
      " [17.01 ]\n",
      " [13.11 ]\n",
      " [15.27 ]\n",
      " [28.11 ]\n",
      " [14.19 ]\n",
      " [13.86 ]\n",
      " [11.89 ]\n",
      " [10.2  ]\n",
      " [19.8  ]\n",
      " [19.53 ]\n",
      " [13.65 ]\n",
      " [13.56 ]\n",
      " [10.18 ]\n",
      " [15.75 ]\n",
      " [14.34 ]\n",
      " [10.44 ]\n",
      " [15.   ]\n",
      " [12.62 ]\n",
      " [12.83 ]\n",
      " [17.05 ]\n",
      " [11.22 ]\n",
      " [ 9.567]\n",
      " [23.21 ]\n",
      " [20.48 ]\n",
      " [14.22 ]\n",
      " [13.64 ]\n",
      " [12.42 ]\n",
      " [11.3  ]\n",
      " [13.75 ]\n",
      " [19.4  ]\n",
      " [10.48 ]\n",
      " [13.2  ]\n",
      " [10.65 ]\n",
      " [11.5  ]\n",
      " [19.73 ]\n",
      " [17.3  ]\n",
      " [19.45 ]\n",
      " [13.96 ]\n",
      " [19.55 ]\n",
      " [15.32 ]\n",
      " [15.66 ]\n",
      " [15.53 ]\n",
      " [20.31 ]\n",
      " [17.35 ]\n",
      " [17.29 ]\n",
      " [20.73 ]\n",
      " [10.6  ]\n",
      " [13.59 ]\n",
      " [10.71 ]\n",
      " [14.29 ]\n",
      " [11.29 ]\n",
      " [ 9.742]\n",
      " [17.93 ]\n",
      " [11.89 ]\n",
      " [11.33 ]\n",
      " [18.81 ]\n",
      " [13.59 ]\n",
      " [13.85 ]\n",
      " [19.16 ]\n",
      " [11.74 ]\n",
      " [19.4  ]\n",
      " [12.89 ]\n",
      " [12.58 ]\n",
      " [11.94 ]\n",
      " [12.89 ]\n",
      " [11.26 ]\n",
      " [11.37 ]\n",
      " [14.41 ]\n",
      " [14.96 ]\n",
      " [12.95 ]\n",
      " [11.85 ]\n",
      " [12.72 ]\n",
      " [13.77 ]\n",
      " [10.91 ]\n",
      " [11.76 ]\n",
      " [10.51 ]\n",
      " [19.53 ]\n",
      " [20.09 ]\n",
      " [10.49 ]\n",
      " [11.46 ]\n",
      " [11.6  ]\n",
      " [13.2  ]\n",
      " [ 9.   ]\n",
      " [13.05 ]\n",
      " [14.61 ]\n",
      " [12.76 ]\n",
      " [11.54 ]\n",
      " [ 8.597]\n",
      " [12.49 ]\n",
      " [12.18 ]\n",
      " [18.22 ]\n",
      " [10.25 ]\n",
      " [20.16 ]\n",
      " [12.86 ]\n",
      " [20.34 ]\n",
      " [12.2  ]\n",
      " [12.67 ]\n",
      " [14.11 ]\n",
      " [12.03 ]\n",
      " [16.27 ]\n",
      " [16.26 ]\n",
      " [12.98 ]\n",
      " [11.22 ]\n",
      " [11.25 ]\n",
      " [12.3  ]\n",
      " [17.06 ]\n",
      " [12.99 ]\n",
      " [10.05 ]\n",
      " [23.51 ]\n",
      " [ 9.606]\n",
      " [11.06 ]\n",
      " [19.68 ]\n",
      " [11.71 ]\n",
      " [12.06 ]\n",
      " [14.76 ]\n",
      " [11.95 ]\n",
      " [15.75 ]\n",
      " [25.73 ]\n",
      " [12.56 ]\n",
      " [13.87 ]\n",
      " [ 9.436]\n",
      " [12.54 ]\n",
      " [13.3  ]\n",
      " [12.76 ]\n",
      " [16.5  ]\n",
      " [20.44 ]\n",
      " [20.2  ]\n",
      " [12.21 ]\n",
      " [21.71 ]\n",
      " [22.01 ]\n",
      " [16.35 ]\n",
      " [15.19 ]\n",
      " [20.64 ]\n",
      " [13.69 ]\n",
      " [16.17 ]\n",
      " [10.57 ]\n",
      " [13.46 ]\n",
      " [13.66 ]\n",
      " [11.08 ]\n",
      " [11.27 ]\n",
      " [11.04 ]\n",
      " [12.39 ]\n",
      " [13.28 ]\n",
      " [12.21 ]\n",
      " [13.88 ]\n",
      " [11.27 ]\n",
      " [10.26 ]\n",
      " [15.49 ]\n",
      " [21.61 ]\n",
      " [12.1  ]\n",
      " [14.06 ]\n",
      " [13.51 ]\n",
      " [12.8  ]\n",
      " [11.06 ]\n",
      " [11.8  ]\n",
      " [12.96 ]\n",
      " [12.94 ]\n",
      " [12.34 ]\n",
      " [10.94 ]\n",
      " [16.14 ]\n",
      " [12.85 ]\n",
      " [17.99 ]\n",
      " [12.27 ]\n",
      " [11.36 ]\n",
      " [11.04 ]\n",
      " [11.89 ]\n",
      " [12.7  ]\n",
      " [11.16 ]\n",
      " [11.61 ]\n",
      " [13.66 ]\n",
      " [ 9.742]\n",
      " [10.03 ]\n",
      " [10.48 ]\n",
      " [10.8  ]\n",
      " [11.13 ]\n",
      " [12.72 ]\n",
      " [14.9  ]\n",
      " [12.4  ]\n",
      " [18.82 ]\n",
      " [13.98 ]\n",
      " [12.87 ]\n",
      " [14.04 ]\n",
      " [13.85 ]\n",
      " [10.97 ]\n",
      " [17.27 ]\n",
      " [13.78 ]\n",
      " [10.57 ]\n",
      " [18.03 ]\n",
      " [11.99 ]\n",
      " [17.75 ]\n",
      " [14.8  ]\n",
      " [14.53 ]\n",
      " [21.1  ]\n",
      " [11.87 ]\n",
      " [19.59 ]\n",
      " [12.   ]\n",
      " [14.53 ]\n",
      " [12.62 ]\n",
      " [13.38 ]\n",
      " [11.63 ]\n",
      " [ 9.755]\n",
      " [17.08 ]\n",
      " [27.42 ]\n",
      " [14.4  ]\n",
      " [13.17 ]\n",
      " [ 9.668]\n",
      " [11.62 ]\n",
      " [ 9.667]\n",
      " [14.92 ]\n",
      " [10.88 ]\n",
      " [12.83 ]\n",
      " [14.2  ]\n",
      " [13.9  ]\n",
      " [11.49 ]\n",
      " [16.25 ]\n",
      " [12.16 ]\n",
      " [13.9  ]\n",
      " [13.7  ]\n",
      " [15.73 ]\n",
      " [12.45 ]\n",
      " [14.64 ]\n",
      " [19.44 ]\n",
      " [11.68 ]\n",
      " [16.69 ]\n",
      " [12.25 ]\n",
      " [17.85 ]\n",
      " [18.01 ]\n",
      " [12.46 ]\n",
      " [13.16 ]\n",
      " [14.87 ]\n",
      " [12.65 ]\n",
      " [12.47 ]\n",
      " [18.49 ]\n",
      " [20.59 ]\n",
      " [13.82 ]\n",
      " [12.54 ]\n",
      " [23.09 ]\n",
      " [ 9.676]\n",
      " [12.22 ]\n",
      " [11.06 ]\n",
      " [16.3  ]\n",
      " [15.46 ]\n",
      " [11.74 ]\n",
      " [14.81 ]\n",
      " [14.58 ]\n",
      " [15.05 ]\n",
      " [19.89 ]\n",
      " [ 9.295]\n",
      " [24.63 ]\n",
      " [11.26 ]\n",
      " [13.71 ]\n",
      " [ 9.847]\n",
      " [13.46 ]\n",
      " [12.34 ]\n",
      " [13.94 ]\n",
      " [12.07 ]\n",
      " [11.75 ]\n",
      " [11.67 ]\n",
      " [13.68 ]\n",
      " [20.47 ]\n",
      " [10.96 ]\n",
      " [20.55 ]\n",
      " [14.27 ]\n",
      " [11.69 ]\n",
      " [ 7.691]\n",
      " [11.54 ]\n",
      " [14.47 ]\n",
      " [14.74 ]\n",
      " [13.21 ]\n",
      " [13.87 ]\n",
      " [13.62 ]\n",
      " [10.26 ]\n",
      " [ 9.683]\n",
      " [10.82 ]\n",
      " [10.86 ]\n",
      " [11.13 ]\n",
      " [12.77 ]\n",
      " [ 9.333]\n",
      " [12.88 ]\n",
      " [10.29 ]\n",
      " [10.16 ]\n",
      " [ 9.423]\n",
      " [14.59 ]\n",
      " [11.51 ]\n",
      " [11.2  ]\n",
      " [20.92 ]\n",
      " [20.13 ]\n",
      " [ 7.76 ]] [1 1 1 1 1 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 1 0 0 0\n",
      " 1 1 1 1 0 1 0 0 1 0 1 0 0 1 1 1 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 1\n",
      " 0 1 1 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1\n",
      " 1 1 1]\n",
      "[[17.99 ]\n",
      " [20.57 ]\n",
      " [19.69 ]\n",
      " [11.42 ]\n",
      " [20.29 ]\n",
      " [12.45 ]\n",
      " [12.46 ]\n",
      " [16.02 ]\n",
      " [15.78 ]\n",
      " [19.17 ]\n",
      " [15.85 ]\n",
      " [13.73 ]\n",
      " [14.54 ]\n",
      " [14.68 ]\n",
      " [16.13 ]\n",
      " [19.81 ]\n",
      " [13.54 ]\n",
      " [ 9.504]\n",
      " [15.34 ]\n",
      " [21.16 ]\n",
      " [16.65 ]\n",
      " [17.14 ]\n",
      " [14.58 ]\n",
      " [18.61 ]\n",
      " [15.3  ]\n",
      " [17.57 ]\n",
      " [11.84 ]\n",
      " [17.02 ]\n",
      " [19.27 ]\n",
      " [16.74 ]\n",
      " [14.25 ]\n",
      " [13.03 ]\n",
      " [13.48 ]\n",
      " [13.44 ]\n",
      " [10.95 ]\n",
      " [19.07 ]\n",
      " [13.28 ]\n",
      " [13.17 ]\n",
      " [18.65 ]\n",
      " [ 8.196]\n",
      " [13.17 ]\n",
      " [12.05 ]\n",
      " [11.76 ]\n",
      " [13.64 ]\n",
      " [11.94 ]\n",
      " [18.22 ]\n",
      " [14.71 ]\n",
      " [13.05 ]\n",
      " [ 8.598]\n",
      " [14.25 ]\n",
      " [ 9.173]\n",
      " [12.68 ]\n",
      " [ 9.465]\n",
      " [11.31 ]\n",
      " [12.78 ]\n",
      " [18.94 ]\n",
      " [ 8.888]\n",
      " [17.2  ]\n",
      " [13.8  ]\n",
      " [12.31 ]\n",
      " [16.07 ]\n",
      " [18.05 ]\n",
      " [20.18 ]\n",
      " [12.86 ]\n",
      " [11.45 ]\n",
      " [13.34 ]\n",
      " [25.22 ]\n",
      " [19.1  ]\n",
      " [12.   ]\n",
      " [18.46 ]\n",
      " [14.48 ]\n",
      " [19.02 ]\n",
      " [12.36 ]\n",
      " [14.64 ]\n",
      " [14.62 ]\n",
      " [15.37 ]\n",
      " [13.27 ]\n",
      " [13.45 ]\n",
      " [15.06 ]\n",
      " [20.26 ]\n",
      " [11.6  ]\n",
      " [14.42 ]\n",
      " [12.18 ]\n",
      " [ 9.876]\n",
      " [10.49 ]\n",
      " [13.11 ]\n",
      " [11.64 ]\n",
      " [12.36 ]\n",
      " [22.27 ]\n",
      " [11.34 ]\n",
      " [ 9.777]\n",
      " [12.63 ]\n",
      " [ 8.726]\n",
      " [11.93 ]\n",
      " [ 8.95 ]\n",
      " [14.87 ]\n",
      " [15.78 ]\n",
      " [17.95 ]\n",
      " [11.41 ]\n",
      " [18.66 ]\n",
      " [24.25 ]\n",
      " [14.5  ]\n",
      " [13.85 ]\n",
      " [19.   ]\n",
      " [15.1  ]\n",
      " [19.79 ]\n",
      " [12.19 ]\n",
      " [15.46 ]\n",
      " [16.16 ]\n",
      " [15.71 ]\n",
      " [18.45 ]\n",
      " [12.77 ]\n",
      " [11.71 ]\n",
      " [14.95 ]\n",
      " [11.28 ]\n",
      " [ 9.738]\n",
      " [16.11 ]\n",
      " [11.43 ]\n",
      " [12.9  ]\n",
      " [11.9  ]\n",
      " [11.8  ]\n",
      " [14.95 ]\n",
      " [14.44 ]\n",
      " [13.74 ]\n",
      " [13.   ]\n",
      " [ 8.219]\n",
      " [ 9.731]\n",
      " [17.68 ]\n",
      " [16.84 ]\n",
      " [10.9  ]\n",
      " [11.75 ]\n",
      " [19.19 ]\n",
      " [12.34 ]\n",
      " [23.27 ]\n",
      " [14.97 ]\n",
      " [10.8  ]\n",
      " [16.78 ]\n",
      " [17.47 ]\n",
      " [14.97 ]\n",
      " [12.32 ]\n",
      " [15.46 ]\n",
      " [11.08 ]\n",
      " [10.66 ]\n",
      " [ 8.671]\n",
      " [ 9.904]\n",
      " [16.46 ]\n",
      " [13.01 ]\n",
      " [12.81 ]\n",
      " [27.22 ]\n",
      " [21.09 ]\n",
      " [15.7  ]\n",
      " [11.41 ]\n",
      " [15.28 ]\n",
      " [11.71 ]\n",
      " [11.81 ]\n",
      " [12.3  ]\n",
      " [12.77 ]\n",
      " [ 9.72 ]\n",
      " [12.34 ]\n",
      " [14.86 ]\n",
      " [12.91 ]\n",
      " [13.77 ]\n",
      " [18.08 ]\n",
      " [19.18 ]\n",
      " [14.45 ]\n",
      " [12.23 ]\n",
      " [17.54 ]\n",
      " [13.81 ]\n",
      " [12.47 ]\n",
      " [15.12 ]\n",
      " [17.01 ]\n",
      " [15.27 ]\n",
      " [20.58 ]\n",
      " [11.84 ]\n",
      " [28.11 ]\n",
      " [17.42 ]\n",
      " [14.19 ]\n",
      " [13.86 ]\n",
      " [11.89 ]\n",
      " [10.2  ]\n",
      " [19.8  ]\n",
      " [19.53 ]\n",
      " [13.65 ]\n",
      " [13.56 ]\n",
      " [10.18 ]\n",
      " [15.75 ]\n",
      " [13.27 ]\n",
      " [10.44 ]\n",
      " [15.   ]\n",
      " [12.62 ]\n",
      " [11.32 ]\n",
      " [11.22 ]\n",
      " [20.51 ]\n",
      " [ 9.567]\n",
      " [14.03 ]\n",
      " [20.48 ]\n",
      " [14.22 ]\n",
      " [17.46 ]\n",
      " [12.42 ]\n",
      " [19.4  ]\n",
      " [10.48 ]\n",
      " [12.89 ]\n",
      " [10.65 ]\n",
      " [11.52 ]\n",
      " [20.94 ]\n",
      " [11.5  ]\n",
      " [17.3  ]\n",
      " [19.45 ]\n",
      " [13.96 ]\n",
      " [19.55 ]\n",
      " [15.32 ]\n",
      " [15.66 ]\n",
      " [15.53 ]\n",
      " [20.31 ]\n",
      " [15.61 ]\n",
      " [17.19 ]\n",
      " [20.73 ]\n",
      " [10.6  ]\n",
      " [13.59 ]\n",
      " [12.87 ]\n",
      " [10.71 ]\n",
      " [14.29 ]\n",
      " [21.75 ]\n",
      " [ 9.742]\n",
      " [17.93 ]\n",
      " [11.89 ]\n",
      " [18.81 ]\n",
      " [13.85 ]\n",
      " [19.16 ]\n",
      " [16.24 ]\n",
      " [12.89 ]\n",
      " [12.58 ]\n",
      " [11.94 ]\n",
      " [12.89 ]\n",
      " [11.26 ]\n",
      " [11.37 ]\n",
      " [14.41 ]\n",
      " [14.96 ]\n",
      " [12.95 ]\n",
      " [12.72 ]\n",
      " [13.77 ]\n",
      " [10.91 ]\n",
      " [11.76 ]\n",
      " [14.26 ]\n",
      " [19.53 ]\n",
      " [12.46 ]\n",
      " [20.09 ]\n",
      " [11.46 ]\n",
      " [11.6  ]\n",
      " [ 9.   ]\n",
      " [13.5  ]\n",
      " [13.05 ]\n",
      " [11.7  ]\n",
      " [14.61 ]\n",
      " [12.76 ]\n",
      " [ 8.597]\n",
      " [12.49 ]\n",
      " [18.22 ]\n",
      " [ 9.042]\n",
      " [12.43 ]\n",
      " [20.16 ]\n",
      " [12.86 ]\n",
      " [20.34 ]\n",
      " [12.2  ]\n",
      " [14.11 ]\n",
      " [12.03 ]\n",
      " [16.27 ]\n",
      " [16.26 ]\n",
      " [16.03 ]\n",
      " [12.98 ]\n",
      " [17.06 ]\n",
      " [18.77 ]\n",
      " [14.42 ]\n",
      " [ 9.606]\n",
      " [11.06 ]\n",
      " [11.71 ]\n",
      " [10.26 ]\n",
      " [11.47 ]\n",
      " [11.95 ]\n",
      " [11.66 ]\n",
      " [15.75 ]\n",
      " [25.73 ]\n",
      " [15.08 ]\n",
      " [11.14 ]\n",
      " [13.05 ]\n",
      " [ 8.878]\n",
      " [ 9.436]\n",
      " [12.54 ]\n",
      " [12.76 ]\n",
      " [16.5  ]\n",
      " [13.4  ]\n",
      " [20.44 ]\n",
      " [21.71 ]\n",
      " [22.01 ]\n",
      " [16.35 ]\n",
      " [15.19 ]\n",
      " [21.37 ]\n",
      " [20.64 ]\n",
      " [13.69 ]\n",
      " [16.17 ]\n",
      " [10.57 ]\n",
      " [13.46 ]\n",
      " [11.08 ]\n",
      " [11.04 ]\n",
      " [12.05 ]\n",
      " [12.39 ]\n",
      " [14.6  ]\n",
      " [12.21 ]\n",
      " [13.88 ]\n",
      " [11.27 ]\n",
      " [19.55 ]\n",
      " [ 8.734]\n",
      " [21.61 ]\n",
      " [12.1  ]\n",
      " [14.06 ]\n",
      " [13.51 ]\n",
      " [12.8  ]\n",
      " [11.06 ]\n",
      " [11.8  ]\n",
      " [17.91 ]\n",
      " [11.93 ]\n",
      " [12.96 ]\n",
      " [12.94 ]\n",
      " [12.34 ]\n",
      " [10.94 ]\n",
      " [12.85 ]\n",
      " [12.27 ]\n",
      " [11.36 ]\n",
      " [11.04 ]\n",
      " [ 9.397]\n",
      " [14.99 ]\n",
      " [15.13 ]\n",
      " [ 9.405]\n",
      " [15.5  ]\n",
      " [12.7  ]\n",
      " [11.16 ]\n",
      " [11.57 ]\n",
      " [14.69 ]\n",
      " [11.61 ]\n",
      " [13.66 ]\n",
      " [ 9.742]\n",
      " [10.03 ]\n",
      " [10.48 ]\n",
      " [11.13 ]\n",
      " [14.9  ]\n",
      " [12.4  ]\n",
      " [20.18 ]\n",
      " [18.82 ]\n",
      " [14.86 ]\n",
      " [13.98 ]\n",
      " [13.85 ]\n",
      " [14.02 ]\n",
      " [13.78 ]\n",
      " [10.57 ]\n",
      " [18.03 ]\n",
      " [11.99 ]\n",
      " [17.75 ]\n",
      " [14.8  ]\n",
      " [14.53 ]\n",
      " [21.1  ]\n",
      " [11.87 ]\n",
      " [19.59 ]\n",
      " [12.   ]\n",
      " [13.38 ]\n",
      " [11.63 ]\n",
      " [13.21 ]\n",
      " [13.   ]\n",
      " [ 9.755]\n",
      " [17.08 ]\n",
      " [27.42 ]\n",
      " [14.4  ]\n",
      " [11.6  ]\n",
      " [13.17 ]\n",
      " [13.24 ]\n",
      " [13.14 ]\n",
      " [ 9.668]\n",
      " [17.6  ]\n",
      " [ 9.667]\n",
      " [12.04 ]\n",
      " [14.92 ]\n",
      " [12.27 ]\n",
      " [12.83 ]\n",
      " [14.2  ]\n",
      " [13.9  ]\n",
      " [16.25 ]\n",
      " [12.16 ]\n",
      " [13.9  ]\n",
      " [13.47 ]\n",
      " [13.7  ]\n",
      " [15.73 ]\n",
      " [12.45 ]\n",
      " [14.64 ]\n",
      " [19.44 ]\n",
      " [11.68 ]\n",
      " [17.85 ]\n",
      " [12.46 ]\n",
      " [13.16 ]\n",
      " [14.87 ]\n",
      " [12.65 ]\n",
      " [12.47 ]\n",
      " [18.49 ]\n",
      " [15.04 ]\n",
      " [13.82 ]\n",
      " [ 9.268]\n",
      " [12.22 ]\n",
      " [11.06 ]\n",
      " [16.3  ]\n",
      " [15.46 ]\n",
      " [11.74 ]\n",
      " [14.81 ]\n",
      " [13.4  ]\n",
      " [14.58 ]\n",
      " [11.34 ]\n",
      " [18.31 ]\n",
      " [19.89 ]\n",
      " [12.88 ]\n",
      " [12.75 ]\n",
      " [ 9.295]\n",
      " [24.63 ]\n",
      " [11.26 ]\n",
      " [ 9.847]\n",
      " [ 8.571]\n",
      " [13.94 ]\n",
      " [12.07 ]\n",
      " [11.75 ]\n",
      " [13.68 ]\n",
      " [20.47 ]\n",
      " [20.55 ]\n",
      " [14.27 ]\n",
      " [11.69 ]\n",
      " [ 7.729]\n",
      " [ 7.691]\n",
      " [11.54 ]\n",
      " [14.47 ]\n",
      " [13.21 ]\n",
      " [13.87 ]\n",
      " [13.62 ]\n",
      " [10.32 ]\n",
      " [ 9.683]\n",
      " [10.82 ]\n",
      " [11.13 ]\n",
      " [12.77 ]\n",
      " [12.88 ]\n",
      " [10.29 ]\n",
      " [10.16 ]\n",
      " [ 9.423]\n",
      " [14.59 ]\n",
      " [11.51 ]\n",
      " [14.05 ]\n",
      " [11.2  ]\n",
      " [15.22 ]\n",
      " [21.56 ]\n",
      " [16.6  ]\n",
      " [20.6  ]\n",
      " [ 7.76 ]] [1 1 1 0 1 1 1 0 1 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 1 1 0\n",
      " 0 0 1 1 1 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 0 1 1]\n",
      "[[17.99 ]\n",
      " [20.57 ]\n",
      " [11.42 ]\n",
      " [18.25 ]\n",
      " [13.71 ]\n",
      " [13.   ]\n",
      " [12.46 ]\n",
      " [16.02 ]\n",
      " [15.78 ]\n",
      " [19.17 ]\n",
      " [15.85 ]\n",
      " [13.73 ]\n",
      " [14.54 ]\n",
      " [14.68 ]\n",
      " [16.13 ]\n",
      " [13.54 ]\n",
      " [13.08 ]\n",
      " [ 9.504]\n",
      " [21.16 ]\n",
      " [16.65 ]\n",
      " [17.14 ]\n",
      " [18.61 ]\n",
      " [15.3  ]\n",
      " [17.57 ]\n",
      " [18.63 ]\n",
      " [11.84 ]\n",
      " [17.02 ]\n",
      " [16.13 ]\n",
      " [14.25 ]\n",
      " [13.03 ]\n",
      " [14.99 ]\n",
      " [13.44 ]\n",
      " [10.95 ]\n",
      " [19.07 ]\n",
      " [13.28 ]\n",
      " [18.65 ]\n",
      " [ 8.196]\n",
      " [13.17 ]\n",
      " [12.05 ]\n",
      " [13.49 ]\n",
      " [11.76 ]\n",
      " [18.22 ]\n",
      " [15.1  ]\n",
      " [11.52 ]\n",
      " [19.21 ]\n",
      " [14.71 ]\n",
      " [13.05 ]\n",
      " [ 8.618]\n",
      " [10.17 ]\n",
      " [14.25 ]\n",
      " [12.68 ]\n",
      " [14.78 ]\n",
      " [ 9.465]\n",
      " [11.31 ]\n",
      " [ 9.029]\n",
      " [12.78 ]\n",
      " [18.94 ]\n",
      " [ 8.888]\n",
      " [17.2  ]\n",
      " [16.07 ]\n",
      " [13.53 ]\n",
      " [18.05 ]\n",
      " [20.18 ]\n",
      " [12.86 ]\n",
      " [11.45 ]\n",
      " [25.22 ]\n",
      " [19.1  ]\n",
      " [12.   ]\n",
      " [18.46 ]\n",
      " [14.48 ]\n",
      " [19.02 ]\n",
      " [14.64 ]\n",
      " [14.62 ]\n",
      " [15.37 ]\n",
      " [15.06 ]\n",
      " [20.26 ]\n",
      " [12.18 ]\n",
      " [ 9.787]\n",
      " [11.6  ]\n",
      " [14.42 ]\n",
      " [13.61 ]\n",
      " [ 6.981]\n",
      " [12.18 ]\n",
      " [ 9.876]\n",
      " [10.49 ]\n",
      " [12.36 ]\n",
      " [22.27 ]\n",
      " [11.34 ]\n",
      " [ 9.777]\n",
      " [12.63 ]\n",
      " [14.26 ]\n",
      " [10.51 ]\n",
      " [11.93 ]\n",
      " [14.87 ]\n",
      " [15.78 ]\n",
      " [17.95 ]\n",
      " [18.66 ]\n",
      " [14.5  ]\n",
      " [13.37 ]\n",
      " [13.85 ]\n",
      " [13.61 ]\n",
      " [19.   ]\n",
      " [15.1  ]\n",
      " [19.79 ]\n",
      " [12.19 ]\n",
      " [15.46 ]\n",
      " [16.16 ]\n",
      " [18.45 ]\n",
      " [11.43 ]\n",
      " [14.95 ]\n",
      " [11.28 ]\n",
      " [ 9.738]\n",
      " [11.43 ]\n",
      " [12.9  ]\n",
      " [10.75 ]\n",
      " [14.95 ]\n",
      " [14.44 ]\n",
      " [13.74 ]\n",
      " [ 8.219]\n",
      " [ 9.731]\n",
      " [11.15 ]\n",
      " [13.15 ]\n",
      " [12.25 ]\n",
      " [17.68 ]\n",
      " [16.84 ]\n",
      " [12.06 ]\n",
      " [10.9  ]\n",
      " [19.19 ]\n",
      " [19.59 ]\n",
      " [12.34 ]\n",
      " [14.97 ]\n",
      " [10.8  ]\n",
      " [14.97 ]\n",
      " [12.32 ]\n",
      " [13.43 ]\n",
      " [15.46 ]\n",
      " [10.66 ]\n",
      " [ 8.671]\n",
      " [16.46 ]\n",
      " [13.01 ]\n",
      " [12.81 ]\n",
      " [27.22 ]\n",
      " [15.7  ]\n",
      " [11.41 ]\n",
      " [15.28 ]\n",
      " [10.08 ]\n",
      " [18.31 ]\n",
      " [11.71 ]\n",
      " [11.81 ]\n",
      " [12.3  ]\n",
      " [14.22 ]\n",
      " [ 9.72 ]\n",
      " [12.34 ]\n",
      " [14.86 ]\n",
      " [13.77 ]\n",
      " [18.08 ]\n",
      " [17.54 ]\n",
      " [23.29 ]\n",
      " [13.81 ]\n",
      " [12.47 ]\n",
      " [15.12 ]\n",
      " [ 9.876]\n",
      " [17.01 ]\n",
      " [13.11 ]\n",
      " [15.27 ]\n",
      " [20.58 ]\n",
      " [11.84 ]\n",
      " [28.11 ]\n",
      " [17.42 ]\n",
      " [14.19 ]\n",
      " [13.86 ]\n",
      " [11.89 ]\n",
      " [10.2  ]\n",
      " [10.18 ]\n",
      " [15.75 ]\n",
      " [13.27 ]\n",
      " [14.34 ]\n",
      " [10.44 ]\n",
      " [15.   ]\n",
      " [12.62 ]\n",
      " [12.83 ]\n",
      " [17.05 ]\n",
      " [11.32 ]\n",
      " [20.51 ]\n",
      " [ 9.567]\n",
      " [14.03 ]\n",
      " [23.21 ]\n",
      " [20.48 ]\n",
      " [17.46 ]\n",
      " [13.64 ]\n",
      " [11.3  ]\n",
      " [13.75 ]\n",
      " [19.4  ]\n",
      " [13.2  ]\n",
      " [12.89 ]\n",
      " [10.65 ]\n",
      " [11.52 ]\n",
      " [20.94 ]\n",
      " [11.5  ]\n",
      " [19.73 ]\n",
      " [19.55 ]\n",
      " [15.32 ]\n",
      " [15.66 ]\n",
      " [15.53 ]\n",
      " [20.31 ]\n",
      " [17.35 ]\n",
      " [17.29 ]\n",
      " [15.61 ]\n",
      " [17.19 ]\n",
      " [20.73 ]\n",
      " [10.6  ]\n",
      " [13.59 ]\n",
      " [12.87 ]\n",
      " [10.71 ]\n",
      " [14.29 ]\n",
      " [11.29 ]\n",
      " [21.75 ]\n",
      " [ 9.742]\n",
      " [17.93 ]\n",
      " [11.89 ]\n",
      " [11.33 ]\n",
      " [18.81 ]\n",
      " [13.59 ]\n",
      " [13.85 ]\n",
      " [19.16 ]\n",
      " [11.74 ]\n",
      " [19.4  ]\n",
      " [16.24 ]\n",
      " [11.94 ]\n",
      " [12.89 ]\n",
      " [11.26 ]\n",
      " [14.96 ]\n",
      " [12.95 ]\n",
      " [11.85 ]\n",
      " [12.72 ]\n",
      " [10.91 ]\n",
      " [14.26 ]\n",
      " [10.51 ]\n",
      " [19.53 ]\n",
      " [12.46 ]\n",
      " [10.49 ]\n",
      " [11.46 ]\n",
      " [11.6  ]\n",
      " [13.2  ]\n",
      " [ 9.   ]\n",
      " [13.5  ]\n",
      " [13.05 ]\n",
      " [11.7  ]\n",
      " [11.54 ]\n",
      " [ 8.597]\n",
      " [12.18 ]\n",
      " [18.22 ]\n",
      " [ 9.042]\n",
      " [12.43 ]\n",
      " [10.25 ]\n",
      " [20.16 ]\n",
      " [20.34 ]\n",
      " [12.2  ]\n",
      " [12.67 ]\n",
      " [14.11 ]\n",
      " [12.03 ]\n",
      " [16.27 ]\n",
      " [16.03 ]\n",
      " [12.98 ]\n",
      " [11.22 ]\n",
      " [11.25 ]\n",
      " [12.3  ]\n",
      " [17.06 ]\n",
      " [12.99 ]\n",
      " [18.77 ]\n",
      " [10.05 ]\n",
      " [23.51 ]\n",
      " [14.42 ]\n",
      " [ 9.606]\n",
      " [19.68 ]\n",
      " [10.26 ]\n",
      " [12.06 ]\n",
      " [14.76 ]\n",
      " [11.47 ]\n",
      " [11.95 ]\n",
      " [11.66 ]\n",
      " [25.73 ]\n",
      " [15.08 ]\n",
      " [11.14 ]\n",
      " [12.56 ]\n",
      " [13.05 ]\n",
      " [13.87 ]\n",
      " [ 8.878]\n",
      " [ 9.436]\n",
      " [12.54 ]\n",
      " [13.3  ]\n",
      " [16.5  ]\n",
      " [13.4  ]\n",
      " [20.2  ]\n",
      " [12.21 ]\n",
      " [21.71 ]\n",
      " [22.01 ]\n",
      " [16.35 ]\n",
      " [15.19 ]\n",
      " [21.37 ]\n",
      " [20.64 ]\n",
      " [13.69 ]\n",
      " [10.57 ]\n",
      " [13.46 ]\n",
      " [13.66 ]\n",
      " [11.27 ]\n",
      " [12.05 ]\n",
      " [12.39 ]\n",
      " [13.28 ]\n",
      " [14.6  ]\n",
      " [13.88 ]\n",
      " [11.27 ]\n",
      " [19.55 ]\n",
      " [10.26 ]\n",
      " [ 8.734]\n",
      " [15.49 ]\n",
      " [12.1  ]\n",
      " [13.51 ]\n",
      " [12.8  ]\n",
      " [11.06 ]\n",
      " [17.91 ]\n",
      " [11.93 ]\n",
      " [12.96 ]\n",
      " [12.34 ]\n",
      " [10.94 ]\n",
      " [16.14 ]\n",
      " [12.85 ]\n",
      " [17.99 ]\n",
      " [11.36 ]\n",
      " [11.04 ]\n",
      " [ 9.397]\n",
      " [14.99 ]\n",
      " [15.13 ]\n",
      " [11.89 ]\n",
      " [ 9.405]\n",
      " [15.5  ]\n",
      " [12.7  ]\n",
      " [11.16 ]\n",
      " [11.57 ]\n",
      " [14.69 ]\n",
      " [11.61 ]\n",
      " [13.66 ]\n",
      " [10.8  ]\n",
      " [12.72 ]\n",
      " [14.9  ]\n",
      " [12.4  ]\n",
      " [20.18 ]\n",
      " [14.86 ]\n",
      " [13.98 ]\n",
      " [12.87 ]\n",
      " [14.04 ]\n",
      " [13.85 ]\n",
      " [14.02 ]\n",
      " [10.97 ]\n",
      " [17.27 ]\n",
      " [13.78 ]\n",
      " [10.57 ]\n",
      " [11.99 ]\n",
      " [17.75 ]\n",
      " [14.8  ]\n",
      " [14.53 ]\n",
      " [21.1  ]\n",
      " [11.87 ]\n",
      " [19.59 ]\n",
      " [14.53 ]\n",
      " [12.62 ]\n",
      " [13.38 ]\n",
      " [11.63 ]\n",
      " [13.21 ]\n",
      " [13.   ]\n",
      " [ 9.755]\n",
      " [17.08 ]\n",
      " [27.42 ]\n",
      " [14.4  ]\n",
      " [11.6  ]\n",
      " [13.24 ]\n",
      " [13.14 ]\n",
      " [17.6  ]\n",
      " [11.62 ]\n",
      " [ 9.667]\n",
      " [12.04 ]\n",
      " [14.92 ]\n",
      " [12.27 ]\n",
      " [10.88 ]\n",
      " [12.83 ]\n",
      " [14.2  ]\n",
      " [11.49 ]\n",
      " [12.16 ]\n",
      " [13.47 ]\n",
      " [13.7  ]\n",
      " [12.45 ]\n",
      " [14.64 ]\n",
      " [11.68 ]\n",
      " [16.69 ]\n",
      " [12.25 ]\n",
      " [18.01 ]\n",
      " [14.87 ]\n",
      " [12.65 ]\n",
      " [12.47 ]\n",
      " [18.49 ]\n",
      " [20.59 ]\n",
      " [15.04 ]\n",
      " [12.54 ]\n",
      " [23.09 ]\n",
      " [ 9.268]\n",
      " [ 9.676]\n",
      " [11.06 ]\n",
      " [15.46 ]\n",
      " [11.74 ]\n",
      " [14.81 ]\n",
      " [13.4  ]\n",
      " [14.58 ]\n",
      " [15.05 ]\n",
      " [11.34 ]\n",
      " [18.31 ]\n",
      " [12.88 ]\n",
      " [12.75 ]\n",
      " [24.63 ]\n",
      " [11.26 ]\n",
      " [13.71 ]\n",
      " [ 9.847]\n",
      " [ 8.571]\n",
      " [13.46 ]\n",
      " [12.34 ]\n",
      " [13.94 ]\n",
      " [12.07 ]\n",
      " [11.67 ]\n",
      " [20.47 ]\n",
      " [10.96 ]\n",
      " [20.55 ]\n",
      " [14.27 ]\n",
      " [11.69 ]\n",
      " [ 7.729]\n",
      " [11.54 ]\n",
      " [14.47 ]\n",
      " [14.74 ]\n",
      " [13.21 ]\n",
      " [13.87 ]\n",
      " [10.32 ]\n",
      " [10.26 ]\n",
      " [10.86 ]\n",
      " [11.13 ]\n",
      " [12.77 ]\n",
      " [ 9.333]\n",
      " [10.16 ]\n",
      " [14.59 ]\n",
      " [11.51 ]\n",
      " [14.05 ]\n",
      " [15.22 ]\n",
      " [20.92 ]\n",
      " [21.56 ]\n",
      " [20.13 ]\n",
      " [16.6  ]\n",
      " [20.6  ]\n",
      " [ 7.76 ]] [1 1 1 1 1 1 1 1 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 0 1 0 1 0 0 1 1 1\n",
      " 0 0 1 0 0 1 1 0 1 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 1 1 0 0 0 0 1 0 0 1 0 1 0\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "[[17.99 ]\n",
      " [20.57 ]\n",
      " [19.69 ]\n",
      " [20.29 ]\n",
      " [12.45 ]\n",
      " [18.25 ]\n",
      " [13.71 ]\n",
      " [13.   ]\n",
      " [12.46 ]\n",
      " [16.02 ]\n",
      " [19.17 ]\n",
      " [13.73 ]\n",
      " [14.54 ]\n",
      " [16.13 ]\n",
      " [19.81 ]\n",
      " [13.08 ]\n",
      " [ 9.504]\n",
      " [15.34 ]\n",
      " [21.16 ]\n",
      " [14.58 ]\n",
      " [15.3  ]\n",
      " [18.63 ]\n",
      " [11.84 ]\n",
      " [19.27 ]\n",
      " [16.13 ]\n",
      " [16.74 ]\n",
      " [13.03 ]\n",
      " [14.99 ]\n",
      " [13.48 ]\n",
      " [19.07 ]\n",
      " [13.28 ]\n",
      " [13.17 ]\n",
      " [18.65 ]\n",
      " [ 8.196]\n",
      " [13.17 ]\n",
      " [12.05 ]\n",
      " [13.49 ]\n",
      " [11.76 ]\n",
      " [13.64 ]\n",
      " [11.94 ]\n",
      " [18.22 ]\n",
      " [15.1  ]\n",
      " [11.52 ]\n",
      " [19.21 ]\n",
      " [14.71 ]\n",
      " [ 8.618]\n",
      " [10.17 ]\n",
      " [ 8.598]\n",
      " [14.25 ]\n",
      " [ 9.173]\n",
      " [12.68 ]\n",
      " [14.78 ]\n",
      " [ 9.465]\n",
      " [ 9.029]\n",
      " [12.78 ]\n",
      " [18.94 ]\n",
      " [ 8.888]\n",
      " [17.2  ]\n",
      " [13.8  ]\n",
      " [12.31 ]\n",
      " [16.07 ]\n",
      " [13.53 ]\n",
      " [20.18 ]\n",
      " [13.34 ]\n",
      " [25.22 ]\n",
      " [12.   ]\n",
      " [18.46 ]\n",
      " [19.02 ]\n",
      " [12.36 ]\n",
      " [14.64 ]\n",
      " [14.62 ]\n",
      " [15.37 ]\n",
      " [13.27 ]\n",
      " [13.45 ]\n",
      " [15.06 ]\n",
      " [20.26 ]\n",
      " [12.18 ]\n",
      " [ 9.787]\n",
      " [11.6  ]\n",
      " [14.42 ]\n",
      " [13.61 ]\n",
      " [ 6.981]\n",
      " [12.18 ]\n",
      " [ 9.876]\n",
      " [13.11 ]\n",
      " [11.64 ]\n",
      " [12.36 ]\n",
      " [22.27 ]\n",
      " [14.26 ]\n",
      " [10.51 ]\n",
      " [ 8.726]\n",
      " [11.93 ]\n",
      " [ 8.95 ]\n",
      " [15.78 ]\n",
      " [17.95 ]\n",
      " [11.41 ]\n",
      " [24.25 ]\n",
      " [14.5  ]\n",
      " [13.37 ]\n",
      " [13.61 ]\n",
      " [19.   ]\n",
      " [15.1  ]\n",
      " [12.19 ]\n",
      " [15.46 ]\n",
      " [16.16 ]\n",
      " [15.71 ]\n",
      " [18.45 ]\n",
      " [12.77 ]\n",
      " [11.71 ]\n",
      " [11.43 ]\n",
      " [ 9.738]\n",
      " [16.11 ]\n",
      " [11.43 ]\n",
      " [12.9  ]\n",
      " [10.75 ]\n",
      " [11.9  ]\n",
      " [11.8  ]\n",
      " [14.95 ]\n",
      " [14.44 ]\n",
      " [13.   ]\n",
      " [ 8.219]\n",
      " [11.15 ]\n",
      " [13.15 ]\n",
      " [12.25 ]\n",
      " [16.84 ]\n",
      " [12.06 ]\n",
      " [10.9  ]\n",
      " [11.75 ]\n",
      " [19.59 ]\n",
      " [12.34 ]\n",
      " [23.27 ]\n",
      " [14.97 ]\n",
      " [16.78 ]\n",
      " [17.47 ]\n",
      " [14.97 ]\n",
      " [12.32 ]\n",
      " [13.43 ]\n",
      " [15.46 ]\n",
      " [11.08 ]\n",
      " [10.66 ]\n",
      " [ 8.671]\n",
      " [ 9.904]\n",
      " [16.46 ]\n",
      " [13.01 ]\n",
      " [12.81 ]\n",
      " [27.22 ]\n",
      " [21.09 ]\n",
      " [11.41 ]\n",
      " [10.08 ]\n",
      " [18.31 ]\n",
      " [11.71 ]\n",
      " [11.81 ]\n",
      " [14.22 ]\n",
      " [12.77 ]\n",
      " [ 9.72 ]\n",
      " [14.86 ]\n",
      " [12.91 ]\n",
      " [13.77 ]\n",
      " [18.08 ]\n",
      " [19.18 ]\n",
      " [14.45 ]\n",
      " [12.23 ]\n",
      " [17.54 ]\n",
      " [23.29 ]\n",
      " [13.81 ]\n",
      " [15.12 ]\n",
      " [ 9.876]\n",
      " [17.01 ]\n",
      " [13.11 ]\n",
      " [15.27 ]\n",
      " [20.58 ]\n",
      " [11.84 ]\n",
      " [17.42 ]\n",
      " [19.8  ]\n",
      " [19.53 ]\n",
      " [13.65 ]\n",
      " [13.56 ]\n",
      " [10.18 ]\n",
      " [13.27 ]\n",
      " [14.34 ]\n",
      " [15.   ]\n",
      " [12.83 ]\n",
      " [17.05 ]\n",
      " [11.32 ]\n",
      " [11.22 ]\n",
      " [20.51 ]\n",
      " [14.03 ]\n",
      " [23.21 ]\n",
      " [14.22 ]\n",
      " [17.46 ]\n",
      " [13.64 ]\n",
      " [12.42 ]\n",
      " [11.3  ]\n",
      " [13.75 ]\n",
      " [19.4  ]\n",
      " [10.48 ]\n",
      " [13.2  ]\n",
      " [12.89 ]\n",
      " [11.52 ]\n",
      " [20.94 ]\n",
      " [19.73 ]\n",
      " [17.3  ]\n",
      " [19.45 ]\n",
      " [13.96 ]\n",
      " [19.55 ]\n",
      " [15.32 ]\n",
      " [17.35 ]\n",
      " [17.29 ]\n",
      " [15.61 ]\n",
      " [17.19 ]\n",
      " [20.73 ]\n",
      " [12.87 ]\n",
      " [14.29 ]\n",
      " [11.29 ]\n",
      " [21.75 ]\n",
      " [ 9.742]\n",
      " [11.33 ]\n",
      " [18.81 ]\n",
      " [13.59 ]\n",
      " [13.85 ]\n",
      " [11.74 ]\n",
      " [19.4  ]\n",
      " [16.24 ]\n",
      " [12.89 ]\n",
      " [12.58 ]\n",
      " [11.26 ]\n",
      " [11.37 ]\n",
      " [14.41 ]\n",
      " [14.96 ]\n",
      " [12.95 ]\n",
      " [11.85 ]\n",
      " [13.77 ]\n",
      " [11.76 ]\n",
      " [14.26 ]\n",
      " [10.51 ]\n",
      " [12.46 ]\n",
      " [20.09 ]\n",
      " [10.49 ]\n",
      " [11.46 ]\n",
      " [11.6  ]\n",
      " [13.2  ]\n",
      " [13.5  ]\n",
      " [11.7  ]\n",
      " [14.61 ]\n",
      " [12.76 ]\n",
      " [11.54 ]\n",
      " [ 8.597]\n",
      " [12.49 ]\n",
      " [12.18 ]\n",
      " [ 9.042]\n",
      " [12.43 ]\n",
      " [10.25 ]\n",
      " [20.16 ]\n",
      " [12.86 ]\n",
      " [12.2  ]\n",
      " [12.67 ]\n",
      " [16.26 ]\n",
      " [16.03 ]\n",
      " [11.22 ]\n",
      " [11.25 ]\n",
      " [12.3  ]\n",
      " [17.06 ]\n",
      " [12.99 ]\n",
      " [18.77 ]\n",
      " [10.05 ]\n",
      " [23.51 ]\n",
      " [14.42 ]\n",
      " [ 9.606]\n",
      " [11.06 ]\n",
      " [19.68 ]\n",
      " [11.71 ]\n",
      " [10.26 ]\n",
      " [12.06 ]\n",
      " [14.76 ]\n",
      " [11.47 ]\n",
      " [11.95 ]\n",
      " [11.66 ]\n",
      " [15.75 ]\n",
      " [15.08 ]\n",
      " [11.14 ]\n",
      " [12.56 ]\n",
      " [13.05 ]\n",
      " [13.87 ]\n",
      " [ 8.878]\n",
      " [ 9.436]\n",
      " [13.3  ]\n",
      " [12.76 ]\n",
      " [13.4  ]\n",
      " [20.44 ]\n",
      " [20.2  ]\n",
      " [12.21 ]\n",
      " [21.71 ]\n",
      " [22.01 ]\n",
      " [16.35 ]\n",
      " [21.37 ]\n",
      " [20.64 ]\n",
      " [16.17 ]\n",
      " [13.46 ]\n",
      " [13.66 ]\n",
      " [11.08 ]\n",
      " [11.27 ]\n",
      " [11.04 ]\n",
      " [12.05 ]\n",
      " [12.39 ]\n",
      " [13.28 ]\n",
      " [14.6  ]\n",
      " [12.21 ]\n",
      " [13.88 ]\n",
      " [11.27 ]\n",
      " [19.55 ]\n",
      " [10.26 ]\n",
      " [ 8.734]\n",
      " [15.49 ]\n",
      " [21.61 ]\n",
      " [12.1  ]\n",
      " [14.06 ]\n",
      " [13.51 ]\n",
      " [12.8  ]\n",
      " [11.06 ]\n",
      " [11.8  ]\n",
      " [17.91 ]\n",
      " [11.93 ]\n",
      " [12.94 ]\n",
      " [10.94 ]\n",
      " [16.14 ]\n",
      " [17.99 ]\n",
      " [12.27 ]\n",
      " [11.04 ]\n",
      " [ 9.397]\n",
      " [14.99 ]\n",
      " [15.13 ]\n",
      " [11.89 ]\n",
      " [ 9.405]\n",
      " [15.5  ]\n",
      " [12.7  ]\n",
      " [11.16 ]\n",
      " [11.57 ]\n",
      " [14.69 ]\n",
      " [13.66 ]\n",
      " [ 9.742]\n",
      " [10.03 ]\n",
      " [10.48 ]\n",
      " [10.8  ]\n",
      " [11.13 ]\n",
      " [12.72 ]\n",
      " [14.9  ]\n",
      " [12.4  ]\n",
      " [20.18 ]\n",
      " [18.82 ]\n",
      " [14.86 ]\n",
      " [12.87 ]\n",
      " [14.04 ]\n",
      " [14.02 ]\n",
      " [10.97 ]\n",
      " [17.27 ]\n",
      " [13.78 ]\n",
      " [18.03 ]\n",
      " [14.53 ]\n",
      " [19.59 ]\n",
      " [12.   ]\n",
      " [14.53 ]\n",
      " [12.62 ]\n",
      " [13.21 ]\n",
      " [13.   ]\n",
      " [ 9.755]\n",
      " [27.42 ]\n",
      " [11.6  ]\n",
      " [13.17 ]\n",
      " [13.24 ]\n",
      " [13.14 ]\n",
      " [ 9.668]\n",
      " [17.6  ]\n",
      " [11.62 ]\n",
      " [12.04 ]\n",
      " [14.92 ]\n",
      " [12.27 ]\n",
      " [10.88 ]\n",
      " [13.9  ]\n",
      " [11.49 ]\n",
      " [16.25 ]\n",
      " [12.16 ]\n",
      " [13.9  ]\n",
      " [13.47 ]\n",
      " [15.73 ]\n",
      " [14.64 ]\n",
      " [19.44 ]\n",
      " [11.68 ]\n",
      " [16.69 ]\n",
      " [12.25 ]\n",
      " [17.85 ]\n",
      " [18.01 ]\n",
      " [12.46 ]\n",
      " [13.16 ]\n",
      " [20.59 ]\n",
      " [15.04 ]\n",
      " [13.82 ]\n",
      " [12.54 ]\n",
      " [23.09 ]\n",
      " [ 9.268]\n",
      " [ 9.676]\n",
      " [12.22 ]\n",
      " [16.3  ]\n",
      " [15.46 ]\n",
      " [11.74 ]\n",
      " [14.81 ]\n",
      " [13.4  ]\n",
      " [15.05 ]\n",
      " [11.34 ]\n",
      " [18.31 ]\n",
      " [19.89 ]\n",
      " [12.88 ]\n",
      " [12.75 ]\n",
      " [ 9.295]\n",
      " [24.63 ]\n",
      " [11.26 ]\n",
      " [13.71 ]\n",
      " [ 8.571]\n",
      " [13.46 ]\n",
      " [12.34 ]\n",
      " [13.94 ]\n",
      " [12.07 ]\n",
      " [11.75 ]\n",
      " [11.67 ]\n",
      " [13.68 ]\n",
      " [10.96 ]\n",
      " [14.27 ]\n",
      " [11.69 ]\n",
      " [ 7.729]\n",
      " [ 7.691]\n",
      " [11.54 ]\n",
      " [14.74 ]\n",
      " [13.21 ]\n",
      " [13.87 ]\n",
      " [13.62 ]\n",
      " [10.32 ]\n",
      " [10.26 ]\n",
      " [ 9.683]\n",
      " [10.82 ]\n",
      " [10.86 ]\n",
      " [11.13 ]\n",
      " [ 9.333]\n",
      " [12.88 ]\n",
      " [10.29 ]\n",
      " [ 9.423]\n",
      " [14.59 ]\n",
      " [11.51 ]\n",
      " [14.05 ]\n",
      " [11.2  ]\n",
      " [15.22 ]\n",
      " [20.92 ]\n",
      " [21.56 ]\n",
      " [20.13 ]\n",
      " [16.6  ]\n",
      " [20.6  ]\n",
      " [ 7.76 ]] [1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 0 0 1 1 0 0 0 0 1 1 0 1 1 0 0 0 1 1 0 1 1\n",
      " 0 1 0 1 1 1 0 0 1 0 0 0 1 0 0 1 1 1 0 0 0 1 0 1 0 0 0 0 1 0 0 1 1 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1\n",
      " 0 0 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20.57 ]\n",
      " [19.69 ]\n",
      " [11.42 ]\n",
      " [20.29 ]\n",
      " [12.45 ]\n",
      " [18.25 ]\n",
      " [13.71 ]\n",
      " [13.   ]\n",
      " [16.02 ]\n",
      " [15.78 ]\n",
      " [19.17 ]\n",
      " [15.85 ]\n",
      " [13.73 ]\n",
      " [14.54 ]\n",
      " [14.68 ]\n",
      " [16.13 ]\n",
      " [19.81 ]\n",
      " [13.54 ]\n",
      " [13.08 ]\n",
      " [ 9.504]\n",
      " [15.34 ]\n",
      " [16.65 ]\n",
      " [17.14 ]\n",
      " [14.58 ]\n",
      " [18.61 ]\n",
      " [17.57 ]\n",
      " [18.63 ]\n",
      " [11.84 ]\n",
      " [17.02 ]\n",
      " [19.27 ]\n",
      " [16.13 ]\n",
      " [16.74 ]\n",
      " [14.25 ]\n",
      " [13.03 ]\n",
      " [14.99 ]\n",
      " [13.48 ]\n",
      " [13.44 ]\n",
      " [10.95 ]\n",
      " [13.17 ]\n",
      " [18.65 ]\n",
      " [ 8.196]\n",
      " [13.49 ]\n",
      " [13.64 ]\n",
      " [11.94 ]\n",
      " [15.1  ]\n",
      " [11.52 ]\n",
      " [19.21 ]\n",
      " [13.05 ]\n",
      " [ 8.618]\n",
      " [10.17 ]\n",
      " [ 8.598]\n",
      " [ 9.173]\n",
      " [12.68 ]\n",
      " [14.78 ]\n",
      " [ 9.465]\n",
      " [11.31 ]\n",
      " [ 9.029]\n",
      " [ 8.888]\n",
      " [13.8  ]\n",
      " [12.31 ]\n",
      " [16.07 ]\n",
      " [13.53 ]\n",
      " [18.05 ]\n",
      " [20.18 ]\n",
      " [12.86 ]\n",
      " [11.45 ]\n",
      " [13.34 ]\n",
      " [19.1  ]\n",
      " [18.46 ]\n",
      " [14.48 ]\n",
      " [12.36 ]\n",
      " [14.64 ]\n",
      " [14.62 ]\n",
      " [13.27 ]\n",
      " [13.45 ]\n",
      " [12.18 ]\n",
      " [ 9.787]\n",
      " [13.61 ]\n",
      " [ 6.981]\n",
      " [12.18 ]\n",
      " [ 9.876]\n",
      " [10.49 ]\n",
      " [13.11 ]\n",
      " [11.64 ]\n",
      " [12.36 ]\n",
      " [22.27 ]\n",
      " [11.34 ]\n",
      " [ 9.777]\n",
      " [12.63 ]\n",
      " [14.26 ]\n",
      " [10.51 ]\n",
      " [ 8.726]\n",
      " [ 8.95 ]\n",
      " [14.87 ]\n",
      " [15.78 ]\n",
      " [11.41 ]\n",
      " [18.66 ]\n",
      " [24.25 ]\n",
      " [13.37 ]\n",
      " [13.85 ]\n",
      " [13.61 ]\n",
      " [19.   ]\n",
      " [19.79 ]\n",
      " [16.16 ]\n",
      " [15.71 ]\n",
      " [18.45 ]\n",
      " [12.77 ]\n",
      " [11.71 ]\n",
      " [11.43 ]\n",
      " [14.95 ]\n",
      " [11.28 ]\n",
      " [ 9.738]\n",
      " [16.11 ]\n",
      " [11.43 ]\n",
      " [10.75 ]\n",
      " [11.9  ]\n",
      " [11.8  ]\n",
      " [13.74 ]\n",
      " [13.   ]\n",
      " [ 9.731]\n",
      " [11.15 ]\n",
      " [13.15 ]\n",
      " [12.25 ]\n",
      " [17.68 ]\n",
      " [16.84 ]\n",
      " [12.06 ]\n",
      " [10.9  ]\n",
      " [11.75 ]\n",
      " [19.19 ]\n",
      " [19.59 ]\n",
      " [23.27 ]\n",
      " [14.97 ]\n",
      " [10.8  ]\n",
      " [16.78 ]\n",
      " [17.47 ]\n",
      " [12.32 ]\n",
      " [13.43 ]\n",
      " [15.46 ]\n",
      " [11.08 ]\n",
      " [ 8.671]\n",
      " [ 9.904]\n",
      " [12.81 ]\n",
      " [21.09 ]\n",
      " [15.7  ]\n",
      " [15.28 ]\n",
      " [10.08 ]\n",
      " [18.31 ]\n",
      " [11.81 ]\n",
      " [12.3  ]\n",
      " [14.22 ]\n",
      " [12.77 ]\n",
      " [12.34 ]\n",
      " [14.86 ]\n",
      " [12.91 ]\n",
      " [13.77 ]\n",
      " [19.18 ]\n",
      " [14.45 ]\n",
      " [12.23 ]\n",
      " [23.29 ]\n",
      " [12.47 ]\n",
      " [15.12 ]\n",
      " [ 9.876]\n",
      " [13.11 ]\n",
      " [20.58 ]\n",
      " [11.84 ]\n",
      " [28.11 ]\n",
      " [17.42 ]\n",
      " [14.19 ]\n",
      " [13.86 ]\n",
      " [11.89 ]\n",
      " [10.2  ]\n",
      " [19.8  ]\n",
      " [19.53 ]\n",
      " [13.65 ]\n",
      " [13.56 ]\n",
      " [15.75 ]\n",
      " [13.27 ]\n",
      " [14.34 ]\n",
      " [10.44 ]\n",
      " [12.62 ]\n",
      " [12.83 ]\n",
      " [17.05 ]\n",
      " [11.32 ]\n",
      " [11.22 ]\n",
      " [20.51 ]\n",
      " [ 9.567]\n",
      " [14.03 ]\n",
      " [23.21 ]\n",
      " [20.48 ]\n",
      " [14.22 ]\n",
      " [17.46 ]\n",
      " [13.64 ]\n",
      " [12.42 ]\n",
      " [11.3  ]\n",
      " [13.75 ]\n",
      " [10.48 ]\n",
      " [13.2  ]\n",
      " [12.89 ]\n",
      " [10.65 ]\n",
      " [11.52 ]\n",
      " [20.94 ]\n",
      " [11.5  ]\n",
      " [19.73 ]\n",
      " [17.3  ]\n",
      " [19.45 ]\n",
      " [13.96 ]\n",
      " [15.66 ]\n",
      " [15.53 ]\n",
      " [20.31 ]\n",
      " [17.35 ]\n",
      " [17.29 ]\n",
      " [15.61 ]\n",
      " [17.19 ]\n",
      " [10.6  ]\n",
      " [13.59 ]\n",
      " [12.87 ]\n",
      " [10.71 ]\n",
      " [11.29 ]\n",
      " [21.75 ]\n",
      " [17.93 ]\n",
      " [11.89 ]\n",
      " [11.33 ]\n",
      " [13.59 ]\n",
      " [19.16 ]\n",
      " [11.74 ]\n",
      " [19.4  ]\n",
      " [16.24 ]\n",
      " [12.89 ]\n",
      " [12.58 ]\n",
      " [11.94 ]\n",
      " [12.89 ]\n",
      " [11.37 ]\n",
      " [14.41 ]\n",
      " [11.85 ]\n",
      " [12.72 ]\n",
      " [13.77 ]\n",
      " [10.91 ]\n",
      " [11.76 ]\n",
      " [14.26 ]\n",
      " [10.51 ]\n",
      " [19.53 ]\n",
      " [12.46 ]\n",
      " [20.09 ]\n",
      " [10.49 ]\n",
      " [13.2  ]\n",
      " [ 9.   ]\n",
      " [13.5  ]\n",
      " [13.05 ]\n",
      " [11.7  ]\n",
      " [14.61 ]\n",
      " [12.76 ]\n",
      " [11.54 ]\n",
      " [12.49 ]\n",
      " [12.18 ]\n",
      " [18.22 ]\n",
      " [ 9.042]\n",
      " [12.43 ]\n",
      " [10.25 ]\n",
      " [12.86 ]\n",
      " [20.34 ]\n",
      " [12.67 ]\n",
      " [14.11 ]\n",
      " [12.03 ]\n",
      " [16.27 ]\n",
      " [16.26 ]\n",
      " [16.03 ]\n",
      " [12.98 ]\n",
      " [11.22 ]\n",
      " [11.25 ]\n",
      " [12.3  ]\n",
      " [12.99 ]\n",
      " [18.77 ]\n",
      " [10.05 ]\n",
      " [23.51 ]\n",
      " [14.42 ]\n",
      " [11.06 ]\n",
      " [19.68 ]\n",
      " [11.71 ]\n",
      " [10.26 ]\n",
      " [12.06 ]\n",
      " [14.76 ]\n",
      " [11.47 ]\n",
      " [11.66 ]\n",
      " [15.75 ]\n",
      " [25.73 ]\n",
      " [15.08 ]\n",
      " [11.14 ]\n",
      " [12.56 ]\n",
      " [13.05 ]\n",
      " [13.87 ]\n",
      " [ 8.878]\n",
      " [12.54 ]\n",
      " [13.3  ]\n",
      " [12.76 ]\n",
      " [16.5  ]\n",
      " [13.4  ]\n",
      " [20.44 ]\n",
      " [20.2  ]\n",
      " [12.21 ]\n",
      " [15.19 ]\n",
      " [21.37 ]\n",
      " [13.69 ]\n",
      " [16.17 ]\n",
      " [10.57 ]\n",
      " [13.66 ]\n",
      " [11.08 ]\n",
      " [11.27 ]\n",
      " [11.04 ]\n",
      " [12.05 ]\n",
      " [13.28 ]\n",
      " [14.6  ]\n",
      " [12.21 ]\n",
      " [19.55 ]\n",
      " [10.26 ]\n",
      " [ 8.734]\n",
      " [15.49 ]\n",
      " [21.61 ]\n",
      " [14.06 ]\n",
      " [11.8  ]\n",
      " [17.91 ]\n",
      " [11.93 ]\n",
      " [12.96 ]\n",
      " [12.94 ]\n",
      " [12.34 ]\n",
      " [16.14 ]\n",
      " [12.85 ]\n",
      " [17.99 ]\n",
      " [12.27 ]\n",
      " [11.36 ]\n",
      " [ 9.397]\n",
      " [14.99 ]\n",
      " [15.13 ]\n",
      " [11.89 ]\n",
      " [ 9.405]\n",
      " [15.5  ]\n",
      " [11.57 ]\n",
      " [14.69 ]\n",
      " [11.61 ]\n",
      " [ 9.742]\n",
      " [10.03 ]\n",
      " [10.48 ]\n",
      " [10.8  ]\n",
      " [11.13 ]\n",
      " [12.72 ]\n",
      " [20.18 ]\n",
      " [18.82 ]\n",
      " [14.86 ]\n",
      " [13.98 ]\n",
      " [12.87 ]\n",
      " [14.04 ]\n",
      " [13.85 ]\n",
      " [14.02 ]\n",
      " [10.97 ]\n",
      " [17.27 ]\n",
      " [10.57 ]\n",
      " [18.03 ]\n",
      " [11.99 ]\n",
      " [17.75 ]\n",
      " [14.8  ]\n",
      " [21.1  ]\n",
      " [11.87 ]\n",
      " [12.   ]\n",
      " [14.53 ]\n",
      " [12.62 ]\n",
      " [13.38 ]\n",
      " [11.63 ]\n",
      " [13.21 ]\n",
      " [13.   ]\n",
      " [17.08 ]\n",
      " [14.4  ]\n",
      " [11.6  ]\n",
      " [13.17 ]\n",
      " [13.24 ]\n",
      " [13.14 ]\n",
      " [ 9.668]\n",
      " [17.6  ]\n",
      " [11.62 ]\n",
      " [ 9.667]\n",
      " [12.04 ]\n",
      " [12.27 ]\n",
      " [10.88 ]\n",
      " [12.83 ]\n",
      " [14.2  ]\n",
      " [13.9  ]\n",
      " [11.49 ]\n",
      " [16.25 ]\n",
      " [13.9  ]\n",
      " [13.47 ]\n",
      " [13.7  ]\n",
      " [15.73 ]\n",
      " [12.45 ]\n",
      " [19.44 ]\n",
      " [16.69 ]\n",
      " [12.25 ]\n",
      " [17.85 ]\n",
      " [18.01 ]\n",
      " [12.46 ]\n",
      " [13.16 ]\n",
      " [14.87 ]\n",
      " [12.65 ]\n",
      " [12.47 ]\n",
      " [18.49 ]\n",
      " [20.59 ]\n",
      " [15.04 ]\n",
      " [13.82 ]\n",
      " [12.54 ]\n",
      " [23.09 ]\n",
      " [ 9.268]\n",
      " [ 9.676]\n",
      " [12.22 ]\n",
      " [11.06 ]\n",
      " [16.3  ]\n",
      " [13.4  ]\n",
      " [14.58 ]\n",
      " [15.05 ]\n",
      " [11.34 ]\n",
      " [18.31 ]\n",
      " [19.89 ]\n",
      " [12.88 ]\n",
      " [12.75 ]\n",
      " [ 9.295]\n",
      " [13.71 ]\n",
      " [ 9.847]\n",
      " [ 8.571]\n",
      " [13.46 ]\n",
      " [12.34 ]\n",
      " [11.75 ]\n",
      " [11.67 ]\n",
      " [13.68 ]\n",
      " [20.47 ]\n",
      " [10.96 ]\n",
      " [20.55 ]\n",
      " [ 7.729]\n",
      " [ 7.691]\n",
      " [14.47 ]\n",
      " [14.74 ]\n",
      " [13.62 ]\n",
      " [10.32 ]\n",
      " [10.26 ]\n",
      " [ 9.683]\n",
      " [10.82 ]\n",
      " [10.86 ]\n",
      " [12.77 ]\n",
      " [ 9.333]\n",
      " [12.88 ]\n",
      " [10.29 ]\n",
      " [10.16 ]\n",
      " [ 9.423]\n",
      " [14.05 ]\n",
      " [11.2  ]\n",
      " [15.22 ]\n",
      " [20.92 ]\n",
      " [21.56 ]\n",
      " [20.13 ]\n",
      " [16.6  ]\n",
      " [20.6  ]] [1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 0 1 1 1 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1\n",
      " 0 1 0 0 0 1 1 1 1 0 0 0 1 1 1 1 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "for train_index, test_index in cv.split(X):\n",
    "    print(X_1[train_index], y[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.88596491, 0.90350877, 0.84210526, 0.88596491, 0.89380531])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=0) \n",
    "scores = cross_val_score(LogisticRegression(), X_1, y, cv=kfold)\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.83478261, 0.84347826, 0.88495575, 0.95575221, 0.92035398])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(LogisticRegression(), X_1, y, cv=5) \n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C' : scores, 'penalty': ['l1','l2']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적의 파라미터:  {'C': 0.9203539823008849, 'penalty': 'l2'}\n",
      "최고 성능 모델:  LogisticRegression(C=0.9203539823008849, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,\n",
      "          solver='warn', tol=0.0001, verbose=0, warm_start=False)\n",
      "최고 교차검증 점수: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5) \n",
    "grid_search.fit(X_1, y)\n",
    "\n",
    "print('최적의 파라미터: ', grid_search.best_params_)\n",
    "print('최고 성능 모델: ', grid_search.best_estimator_)\n",
    "print('최고 교차검증 점수: {:.2f}'.format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean_fit_time</th>\n",
       "      <td>0.0250007</td>\n",
       "      <td>0.00312333</td>\n",
       "      <td>0.0187463</td>\n",
       "      <td>0.00624442</td>\n",
       "      <td>0.0437489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_fit_time</th>\n",
       "      <td>0.0124999</td>\n",
       "      <td>0.00624666</td>\n",
       "      <td>0.00625271</td>\n",
       "      <td>0.00764783</td>\n",
       "      <td>0.0182212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_score_time</th>\n",
       "      <td>0.00312581</td>\n",
       "      <td>0.00312414</td>\n",
       "      <td>0.00626035</td>\n",
       "      <td>0.00312576</td>\n",
       "      <td>0.00624819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_score_time</th>\n",
       "      <td>0.00625162</td>\n",
       "      <td>0.00624828</td>\n",
       "      <td>0.00766733</td>\n",
       "      <td>0.00625153</td>\n",
       "      <td>0.00765244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_C</th>\n",
       "      <td>0.834783</td>\n",
       "      <td>0.834783</td>\n",
       "      <td>0.843478</td>\n",
       "      <td>0.843478</td>\n",
       "      <td>0.884956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_penalty</th>\n",
       "      <td>l1</td>\n",
       "      <td>l2</td>\n",
       "      <td>l1</td>\n",
       "      <td>l2</td>\n",
       "      <td>l1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <td>{'C': 0.8347826086956521, 'penalty': 'l1'}</td>\n",
       "      <td>{'C': 0.8347826086956521, 'penalty': 'l2'}</td>\n",
       "      <td>{'C': 0.8434782608695652, 'penalty': 'l1'}</td>\n",
       "      <td>{'C': 0.8434782608695652, 'penalty': 'l2'}</td>\n",
       "      <td>{'C': 0.8849557522123894, 'penalty': 'l1'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_test_score</th>\n",
       "      <td>0.834783</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.834783</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.834783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_score</th>\n",
       "      <td>0.843478</td>\n",
       "      <td>0.843478</td>\n",
       "      <td>0.843478</td>\n",
       "      <td>0.843478</td>\n",
       "      <td>0.843478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_test_score</th>\n",
       "      <td>0.884956</td>\n",
       "      <td>0.876106</td>\n",
       "      <td>0.884956</td>\n",
       "      <td>0.876106</td>\n",
       "      <td>0.884956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_test_score</th>\n",
       "      <td>0.920354</td>\n",
       "      <td>0.946903</td>\n",
       "      <td>0.920354</td>\n",
       "      <td>0.946903</td>\n",
       "      <td>0.920354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_test_score</th>\n",
       "      <td>0.902655</td>\n",
       "      <td>0.920354</td>\n",
       "      <td>0.902655</td>\n",
       "      <td>0.920354</td>\n",
       "      <td>0.902655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_score</th>\n",
       "      <td>0.876977</td>\n",
       "      <td>0.88225</td>\n",
       "      <td>0.876977</td>\n",
       "      <td>0.88225</td>\n",
       "      <td>0.876977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_score</th>\n",
       "      <td>0.0332247</td>\n",
       "      <td>0.0454674</td>\n",
       "      <td>0.0332247</td>\n",
       "      <td>0.0454674</td>\n",
       "      <td>0.0332247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_train_score</th>\n",
       "      <td>0.900881</td>\n",
       "      <td>0.89207</td>\n",
       "      <td>0.900881</td>\n",
       "      <td>0.89207</td>\n",
       "      <td>0.900881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_train_score</th>\n",
       "      <td>0.889868</td>\n",
       "      <td>0.89207</td>\n",
       "      <td>0.889868</td>\n",
       "      <td>0.89207</td>\n",
       "      <td>0.889868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_train_score</th>\n",
       "      <td>0.881579</td>\n",
       "      <td>0.883772</td>\n",
       "      <td>0.881579</td>\n",
       "      <td>0.883772</td>\n",
       "      <td>0.881579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_train_score</th>\n",
       "      <td>0.870614</td>\n",
       "      <td>0.870614</td>\n",
       "      <td>0.870614</td>\n",
       "      <td>0.870614</td>\n",
       "      <td>0.868421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_train_score</th>\n",
       "      <td>0.870614</td>\n",
       "      <td>0.879386</td>\n",
       "      <td>0.870614</td>\n",
       "      <td>0.879386</td>\n",
       "      <td>0.870614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_score</th>\n",
       "      <td>0.882711</td>\n",
       "      <td>0.883583</td>\n",
       "      <td>0.882711</td>\n",
       "      <td>0.883583</td>\n",
       "      <td>0.882273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_train_score</th>\n",
       "      <td>0.0116218</td>\n",
       "      <td>0.00812305</td>\n",
       "      <td>0.0116218</td>\n",
       "      <td>0.00812305</td>\n",
       "      <td>0.0121015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             0  \\\n",
       "mean_fit_time                                        0.0250007   \n",
       "std_fit_time                                         0.0124999   \n",
       "mean_score_time                                     0.00312581   \n",
       "std_score_time                                      0.00625162   \n",
       "param_C                                               0.834783   \n",
       "param_penalty                                               l1   \n",
       "params              {'C': 0.8347826086956521, 'penalty': 'l1'}   \n",
       "split0_test_score                                     0.834783   \n",
       "split1_test_score                                     0.843478   \n",
       "split2_test_score                                     0.884956   \n",
       "split3_test_score                                     0.920354   \n",
       "split4_test_score                                     0.902655   \n",
       "mean_test_score                                       0.876977   \n",
       "std_test_score                                       0.0332247   \n",
       "rank_test_score                                              6   \n",
       "split0_train_score                                    0.900881   \n",
       "split1_train_score                                    0.889868   \n",
       "split2_train_score                                    0.881579   \n",
       "split3_train_score                                    0.870614   \n",
       "split4_train_score                                    0.870614   \n",
       "mean_train_score                                      0.882711   \n",
       "std_train_score                                      0.0116218   \n",
       "\n",
       "                                                             1  \\\n",
       "mean_fit_time                                       0.00312333   \n",
       "std_fit_time                                        0.00624666   \n",
       "mean_score_time                                     0.00312414   \n",
       "std_score_time                                      0.00624828   \n",
       "param_C                                               0.834783   \n",
       "param_penalty                                               l2   \n",
       "params              {'C': 0.8347826086956521, 'penalty': 'l2'}   \n",
       "split0_test_score                                     0.826087   \n",
       "split1_test_score                                     0.843478   \n",
       "split2_test_score                                     0.876106   \n",
       "split3_test_score                                     0.946903   \n",
       "split4_test_score                                     0.920354   \n",
       "mean_test_score                                        0.88225   \n",
       "std_test_score                                       0.0454674   \n",
       "rank_test_score                                              4   \n",
       "split0_train_score                                     0.89207   \n",
       "split1_train_score                                     0.89207   \n",
       "split2_train_score                                    0.883772   \n",
       "split3_train_score                                    0.870614   \n",
       "split4_train_score                                    0.879386   \n",
       "mean_train_score                                      0.883583   \n",
       "std_train_score                                     0.00812305   \n",
       "\n",
       "                                                             2  \\\n",
       "mean_fit_time                                        0.0187463   \n",
       "std_fit_time                                        0.00625271   \n",
       "mean_score_time                                     0.00626035   \n",
       "std_score_time                                      0.00766733   \n",
       "param_C                                               0.843478   \n",
       "param_penalty                                               l1   \n",
       "params              {'C': 0.8434782608695652, 'penalty': 'l1'}   \n",
       "split0_test_score                                     0.834783   \n",
       "split1_test_score                                     0.843478   \n",
       "split2_test_score                                     0.884956   \n",
       "split3_test_score                                     0.920354   \n",
       "split4_test_score                                     0.902655   \n",
       "mean_test_score                                       0.876977   \n",
       "std_test_score                                       0.0332247   \n",
       "rank_test_score                                              6   \n",
       "split0_train_score                                    0.900881   \n",
       "split1_train_score                                    0.889868   \n",
       "split2_train_score                                    0.881579   \n",
       "split3_train_score                                    0.870614   \n",
       "split4_train_score                                    0.870614   \n",
       "mean_train_score                                      0.882711   \n",
       "std_train_score                                      0.0116218   \n",
       "\n",
       "                                                             3  \\\n",
       "mean_fit_time                                       0.00624442   \n",
       "std_fit_time                                        0.00764783   \n",
       "mean_score_time                                     0.00312576   \n",
       "std_score_time                                      0.00625153   \n",
       "param_C                                               0.843478   \n",
       "param_penalty                                               l2   \n",
       "params              {'C': 0.8434782608695652, 'penalty': 'l2'}   \n",
       "split0_test_score                                     0.826087   \n",
       "split1_test_score                                     0.843478   \n",
       "split2_test_score                                     0.876106   \n",
       "split3_test_score                                     0.946903   \n",
       "split4_test_score                                     0.920354   \n",
       "mean_test_score                                        0.88225   \n",
       "std_test_score                                       0.0454674   \n",
       "rank_test_score                                              4   \n",
       "split0_train_score                                     0.89207   \n",
       "split1_train_score                                     0.89207   \n",
       "split2_train_score                                    0.883772   \n",
       "split3_train_score                                    0.870614   \n",
       "split4_train_score                                    0.879386   \n",
       "mean_train_score                                      0.883583   \n",
       "std_train_score                                     0.00812305   \n",
       "\n",
       "                                                             4  \n",
       "mean_fit_time                                        0.0437489  \n",
       "std_fit_time                                         0.0182212  \n",
       "mean_score_time                                     0.00624819  \n",
       "std_score_time                                      0.00765244  \n",
       "param_C                                               0.884956  \n",
       "param_penalty                                               l1  \n",
       "params              {'C': 0.8849557522123894, 'penalty': 'l1'}  \n",
       "split0_test_score                                     0.834783  \n",
       "split1_test_score                                     0.843478  \n",
       "split2_test_score                                     0.884956  \n",
       "split3_test_score                                     0.920354  \n",
       "split4_test_score                                     0.902655  \n",
       "mean_test_score                                       0.876977  \n",
       "std_test_score                                       0.0332247  \n",
       "rank_test_score                                              6  \n",
       "split0_train_score                                    0.900881  \n",
       "split1_train_score                                    0.889868  \n",
       "split2_train_score                                    0.881579  \n",
       "split3_train_score                                    0.868421  \n",
       "split4_train_score                                    0.870614  \n",
       "mean_train_score                                      0.882273  \n",
       "std_train_score                                      0.0121015  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "display(np.transpose(results.head()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
